{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "027cbccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from numpy import random as rd\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "   \n",
    "def get_accuracy_estimate(truths, predicted):\n",
    "\n",
    "    print(classification_report(truths, predicted))\n",
    "    print(' TEXT Classifier Accuracy: ', accuracy_score(truths, predicted))\n",
    "\n",
    "    print('f1_score micro: ', f1_score(truths, predicted, average='micro'))\n",
    "    print('f1_score macro: ', f1_score(truths, predicted, average='macro'))    \n",
    "    print('f1_score wieghted: ', f1_score(truths, predicted, average='weighted'))        \n",
    "\n",
    "    return f1_score(truths, predicted, average='micro'), f1_score(truths, predicted, average='macro'), f1_score(truths, predicted, average='weighted')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c13256",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b59902c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>response_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>interaction_type</th>\n",
       "      <th>label</th>\n",
       "      <th>label_expanded</th>\n",
       "      <th>Confidence_Level</th>\n",
       "      <th>response_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>...</th>\n",
       "      <th>response_user</th>\n",
       "      <th>target_user_embedding</th>\n",
       "      <th>response_user_embedding</th>\n",
       "      <th>target_user_embedding_8</th>\n",
       "      <th>response_user_embedding_8</th>\n",
       "      <th>present_in_train</th>\n",
       "      <th>np_response_text_ada_embedding</th>\n",
       "      <th>np_target_text_ada_embedding</th>\n",
       "      <th>np_target_user_embedding</th>\n",
       "      <th>np_response_user_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>997626508050157568</td>\n",
       "      <td>997598447376175104</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Support</td>\n",
       "      <td>Implicit_Support</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Seriously, wtf is wrong with our political sys...</td>\n",
       "      <td>More children have been killed in schools this...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>18655355</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>None</td>\n",
       "      <td>[-0.025092221796512604, -0.013276644051074982,...</td>\n",
       "      <td>[-0.008838048204779625, -0.003347944701090455,...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>997575042027458561</td>\n",
       "      <td>997573240380968961</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Denial</td>\n",
       "      <td>Explicit_Denial</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ma calls BS! https://t.co/bodEWN5Q4C</td>\n",
       "      <td>Former GOP Rep. Jason Chaffetz: 'Politically c...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>3176702526</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.2439490556716919, -0.44223514199256897, 0.1...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.2439490556716919, -0.44223514199256897, 0.1...</td>\n",
       "      <td>None</td>\n",
       "      <td>[-0.033440690487623215, 0.007639116141945124, ...</td>\n",
       "      <td>[-0.027197668328881264, 0.0034390492364764214,...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.2439490556716919, -0.44223514199256897, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>997540582846271494</td>\n",
       "      <td>997535659870117888</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Denial</td>\n",
       "      <td>Explicit_Denial</td>\n",
       "      <td>1.0</td>\n",
       "      <td>On average, there’s one fake stat about school...</td>\n",
       "      <td>On average, that’s one school shooting every w...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1646856415</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>None</td>\n",
       "      <td>[-0.023548724129796028, 0.022269316017627716, ...</td>\n",
       "      <td>[-0.0044773295521736145, -0.014855715446174145...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>General_Terms</td>\n",
       "      <td>1018569947817992192</td>\n",
       "      <td>1017909301040635904</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Denial</td>\n",
       "      <td>Implicit_Denial</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ONE MIGHT BE MADE UP AND NOT REAL. NOT SURE. S...</td>\n",
       "      <td>I’m so confused... - When we were attacked on ...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>766475610059317248</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.004989785607904196, -0.004917326848953962, ...</td>\n",
       "      <td>[-0.013004736974835396, -0.01780531369149685, ...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General_Terms</td>\n",
       "      <td>1019395289575239680</td>\n",
       "      <td>1017919759474622464</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Denial</td>\n",
       "      <td>Explicit_Denial</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False, adult friendships are M-F, 9-5 https://...</td>\n",
       "      <td>Adult friendships https://t.co/Cn3r9l4pZJ</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>59621769</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.023379407823085785, 0.010180916637182236, -...</td>\n",
       "      <td>[0.01642121560871601, 0.0012021968141198158, 0...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5045</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>997648170774654976</td>\n",
       "      <td>997645387669299200</td>\n",
       "      <td>Reply</td>\n",
       "      <td>Comment</td>\n",
       "      <td>Comment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>@cenkuygur @realDonaldTrump @NRA NRA is funded...</td>\n",
       "      <td>Hey #MAGA guys, I thought @realDonaldTrump was...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2948973487</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>None</td>\n",
       "      <td>[-0.03429972380399704, 0.0034139070194214582, ...</td>\n",
       "      <td>[-0.039812665432691574, 0.005698402877897024, ...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5046</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>998085810636259328</td>\n",
       "      <td>997484633695469570</td>\n",
       "      <td>Reply</td>\n",
       "      <td>Comment</td>\n",
       "      <td>Comment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>@ScottMcGrew There is no right answer to this ...</td>\n",
       "      <td>Guns and prayers: A man shows up to the Santa ...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>103706087</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>None</td>\n",
       "      <td>[-0.023522792384028435, 0.003550187451764941, ...</td>\n",
       "      <td>[-0.017941860482096672, 0.003447071649134159, ...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5047</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>998318329474400256</td>\n",
       "      <td>998316225435504640</td>\n",
       "      <td>Reply</td>\n",
       "      <td>Comment</td>\n",
       "      <td>Comment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>@cameron_kasky @NRA Sadly, there’s also so muc...</td>\n",
       "      <td>It makes me so furious how the @NRA behaves as...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>412350904</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.004335987847298384, -0.008479560725390911, ...</td>\n",
       "      <td>[-0.030558191239833832, -0.010756535455584526,...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>999387940890578945</td>\n",
       "      <td>999321499470368768</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Comment</td>\n",
       "      <td>Comment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>What is freaking wrong w/the prior administrat...</td>\n",
       "      <td>BREAKING: Emails reveal cynical exchange betwe...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>975247231925223424</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>None</td>\n",
       "      <td>[-0.005231035407632589, -0.024064065888524055,...</td>\n",
       "      <td>[-0.030978472903370857, -0.01256611943244934, ...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5049</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>999961330223370240</td>\n",
       "      <td>999174354939326465</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Comment</td>\n",
       "      <td>Comment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>So, so sad. And wrong. https://t.co/EzqwQasWJb</td>\n",
       "      <td>One of the 10 victims in the Santa Fe High Sch...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>952652730</td>\n",
       "      <td>[0.1230868548154831, -0.5258405804634094, 0.18...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>[0.1230868548154831, -0.5258405804634094, 0.18...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.0007300913566723466, -0.002659472869709134,...</td>\n",
       "      <td>[-0.007391271181404591, -0.0037286323495209217...</td>\n",
       "      <td>[0.1230868548154831, -0.5258405804634094, 0.18...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5050 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  event          response_id            target_id  \\\n",
       "0     Santa_Fe_Shooting   997626508050157568   997598447376175104   \n",
       "1     Santa_Fe_Shooting   997575042027458561   997573240380968961   \n",
       "2     Santa_Fe_Shooting   997540582846271494   997535659870117888   \n",
       "3         General_Terms  1018569947817992192  1017909301040635904   \n",
       "4         General_Terms  1019395289575239680  1017919759474622464   \n",
       "...                 ...                  ...                  ...   \n",
       "5045  Santa_Fe_Shooting   997648170774654976   997645387669299200   \n",
       "5046  Santa_Fe_Shooting   998085810636259328   997484633695469570   \n",
       "5047  Santa_Fe_Shooting   998318329474400256   998316225435504640   \n",
       "5048  Santa_Fe_Shooting   999387940890578945   999321499470368768   \n",
       "5049  Santa_Fe_Shooting   999961330223370240   999174354939326465   \n",
       "\n",
       "     interaction_type    label    label_expanded Confidence_Level  \\\n",
       "0               Quote  Support  Implicit_Support              1.0   \n",
       "1               Quote   Denial   Explicit_Denial              1.0   \n",
       "2               Quote   Denial   Explicit_Denial              1.0   \n",
       "3               Quote   Denial   Implicit_Denial              1.0   \n",
       "4               Quote   Denial   Explicit_Denial              1.0   \n",
       "...               ...      ...               ...              ...   \n",
       "5045            Reply  Comment           Comment              2.0   \n",
       "5046            Reply  Comment           Comment              2.0   \n",
       "5047            Reply  Comment           Comment              2.0   \n",
       "5048            Quote  Comment           Comment              2.0   \n",
       "5049            Quote  Comment           Comment              2.0   \n",
       "\n",
       "                                          response_text  \\\n",
       "0     Seriously, wtf is wrong with our political sys...   \n",
       "1                  Ma calls BS! https://t.co/bodEWN5Q4C   \n",
       "2     On average, there’s one fake stat about school...   \n",
       "3     ONE MIGHT BE MADE UP AND NOT REAL. NOT SURE. S...   \n",
       "4     False, adult friendships are M-F, 9-5 https://...   \n",
       "...                                                 ...   \n",
       "5045  @cenkuygur @realDonaldTrump @NRA NRA is funded...   \n",
       "5046  @ScottMcGrew There is no right answer to this ...   \n",
       "5047  @cameron_kasky @NRA Sadly, there’s also so muc...   \n",
       "5048  What is freaking wrong w/the prior administrat...   \n",
       "5049     So, so sad. And wrong. https://t.co/EzqwQasWJb   \n",
       "\n",
       "                                            target_text  truncated  ...  \\\n",
       "0     More children have been killed in schools this...      False  ...   \n",
       "1     Former GOP Rep. Jason Chaffetz: 'Politically c...      False  ...   \n",
       "2     On average, that’s one school shooting every w...      False  ...   \n",
       "3     I’m so confused... - When we were attacked on ...      False  ...   \n",
       "4             Adult friendships https://t.co/Cn3r9l4pZJ      False  ...   \n",
       "...                                                 ...        ...  ...   \n",
       "5045  Hey #MAGA guys, I thought @realDonaldTrump was...      False  ...   \n",
       "5046  Guns and prayers: A man shows up to the Santa ...      False  ...   \n",
       "5047  It makes me so furious how the @NRA behaves as...      False  ...   \n",
       "5048  BREAKING: Emails reveal cynical exchange betwe...      False  ...   \n",
       "5049  One of the 10 victims in the Santa Fe High Sch...      False  ...   \n",
       "\n",
       "           response_user                              target_user_embedding  \\\n",
       "0               18655355  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "1             3176702526  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "2             1646856415  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "3     766475610059317248  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "4               59621769  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "...                  ...                                                ...   \n",
       "5045          2948973487  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "5046           103706087  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "5047           412350904  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "5048  975247231925223424  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "5049           952652730  [0.1230868548154831, -0.5258405804634094, 0.18...   \n",
       "\n",
       "                                response_user_embedding  \\\n",
       "0     [0.1620851755142212, -0.4702264964580536, 0.21...   \n",
       "1     [0.2439490556716919, -0.44223514199256897, 0.1...   \n",
       "2     [0.1620851755142212, -0.4702264964580536, 0.21...   \n",
       "3     [0.1620851755142212, -0.4702264964580536, 0.21...   \n",
       "4     [0.1620851755142212, -0.4702264964580536, 0.21...   \n",
       "...                                                 ...   \n",
       "5045  [0.1620851755142212, -0.4702264964580536, 0.21...   \n",
       "5046  [0.1620851755142212, -0.4702264964580536, 0.21...   \n",
       "5047  [0.1620851755142212, -0.4702264964580536, 0.21...   \n",
       "5048  [0.1620851755142212, -0.4702264964580536, 0.21...   \n",
       "5049  [0.1620851755142212, -0.4702264964580536, 0.21...   \n",
       "\n",
       "                                target_user_embedding_8  \\\n",
       "0     [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "1     [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "2     [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "3     [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "4     [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "...                                                 ...   \n",
       "5045  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "5046  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "5047  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "5048  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "5049  [0.1230868548154831, -0.5258405804634094, 0.18...   \n",
       "\n",
       "                              response_user_embedding_8 present_in_train  \\\n",
       "0     [0.1620851755142212, -0.4702264964580536, 0.21...             None   \n",
       "1     [0.2439490556716919, -0.44223514199256897, 0.1...             None   \n",
       "2     [0.1620851755142212, -0.4702264964580536, 0.21...             None   \n",
       "3     [0.1620851755142212, -0.4702264964580536, 0.21...             None   \n",
       "4     [0.1620851755142212, -0.4702264964580536, 0.21...             None   \n",
       "...                                                 ...              ...   \n",
       "5045  [0.1620851755142212, -0.4702264964580536, 0.21...             None   \n",
       "5046  [0.1620851755142212, -0.4702264964580536, 0.21...             None   \n",
       "5047  [0.1620851755142212, -0.4702264964580536, 0.21...             None   \n",
       "5048  [0.1620851755142212, -0.4702264964580536, 0.21...             None   \n",
       "5049  [0.1620851755142212, -0.4702264964580536, 0.21...             None   \n",
       "\n",
       "                         np_response_text_ada_embedding  \\\n",
       "0     [-0.025092221796512604, -0.013276644051074982,...   \n",
       "1     [-0.033440690487623215, 0.007639116141945124, ...   \n",
       "2     [-0.023548724129796028, 0.022269316017627716, ...   \n",
       "3     [0.004989785607904196, -0.004917326848953962, ...   \n",
       "4     [0.023379407823085785, 0.010180916637182236, -...   \n",
       "...                                                 ...   \n",
       "5045  [-0.03429972380399704, 0.0034139070194214582, ...   \n",
       "5046  [-0.023522792384028435, 0.003550187451764941, ...   \n",
       "5047  [0.004335987847298384, -0.008479560725390911, ...   \n",
       "5048  [-0.005231035407632589, -0.024064065888524055,...   \n",
       "5049  [0.0007300913566723466, -0.002659472869709134,...   \n",
       "\n",
       "                           np_target_text_ada_embedding  \\\n",
       "0     [-0.008838048204779625, -0.003347944701090455,...   \n",
       "1     [-0.027197668328881264, 0.0034390492364764214,...   \n",
       "2     [-0.0044773295521736145, -0.014855715446174145...   \n",
       "3     [-0.013004736974835396, -0.01780531369149685, ...   \n",
       "4     [0.01642121560871601, 0.0012021968141198158, 0...   \n",
       "...                                                 ...   \n",
       "5045  [-0.039812665432691574, 0.005698402877897024, ...   \n",
       "5046  [-0.017941860482096672, 0.003447071649134159, ...   \n",
       "5047  [-0.030558191239833832, -0.010756535455584526,...   \n",
       "5048  [-0.030978472903370857, -0.01256611943244934, ...   \n",
       "5049  [-0.007391271181404591, -0.0037286323495209217...   \n",
       "\n",
       "                               np_target_user_embedding  \\\n",
       "0     [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "1     [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "2     [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "3     [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "4     [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "...                                                 ...   \n",
       "5045  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "5046  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "5047  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "5048  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "5049  [0.1230868548154831, -0.5258405804634094, 0.18...   \n",
       "\n",
       "                             np_response_user_embedding  \n",
       "0     [0.1620851755142212, -0.4702264964580536, 0.21...  \n",
       "1     [0.2439490556716919, -0.44223514199256897, 0.1...  \n",
       "2     [0.1620851755142212, -0.4702264964580536, 0.21...  \n",
       "3     [0.1620851755142212, -0.4702264964580536, 0.21...  \n",
       "4     [0.1620851755142212, -0.4702264964580536, 0.21...  \n",
       "...                                                 ...  \n",
       "5045  [0.1620851755142212, -0.4702264964580536, 0.21...  \n",
       "5046  [0.1620851755142212, -0.4702264964580536, 0.21...  \n",
       "5047  [0.1620851755142212, -0.4702264964580536, 0.21...  \n",
       "5048  [0.1620851755142212, -0.4702264964580536, 0.21...  \n",
       "5049  [0.1620851755142212, -0.4702264964580536, 0.21...  \n",
       "\n",
       "[5050 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/Contentious_pairs_all.csv', encoding=\"utf-8\", \n",
    "                 dtype={\"response_id\":str, \"target_id\":str,\n",
    "                       \"response_user\":str, \"target_user\":str} ).fillna('')\n",
    "\n",
    "\n",
    "df['present_in_train'] = None\n",
    "df['np_response_text_ada_embedding'] = df['response_text_ada_embedding'].apply(eval).apply(np.array)\n",
    "df['np_target_text_ada_embedding'] = df['target_text_ada_embedding'].apply(eval).apply(np.array)\n",
    "\n",
    "df['np_target_user_embedding'] = df['target_user_embedding_8'].apply(eval).apply(np.array)\n",
    "df['np_response_user_embedding'] = df['response_user_embedding_8'].apply(eval).apply(np.array)\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea672c6",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "299ca0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from torch import nn\n",
    "import torch as T\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from random import sample\n",
    "\n",
    "\n",
    "device = T.device('cpu')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# X, y = get_data(...)\n",
    "# y_pred = model.predict(X)\n",
    "# f1_score(y, y_pred)\n",
    "\n",
    "LEARNING_RATE = 1e-2\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "\n",
    "def accuracy_fn(y_pred, y_true):\n",
    "    n_correct = torch.eq(y_pred, y_true).sum().item()\n",
    "    accuracy = (n_correct / len(y_pred)) * 100\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim,hidden_dim2, num_classes):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc12 = nn.Linear(hidden_dim, hidden_dim2)        \n",
    "        self.fc13 = nn.Linear( hidden_dim2, hidden_dim2)                \n",
    "        self.fc2 = nn.Linear(hidden_dim2, num_classes)\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        z = F.relu(self.fc1(x_in)) # linear activation\n",
    "        z1 = F.relu(self.fc12(z))        \n",
    "        z12 = F.relu(self.fc13(z1))          \n",
    "        z2 = self.fc2(z12)        \n",
    "        return [z1, z2]\n",
    "    \n",
    "\n",
    "class ContrastiveLoss(T.nn.Module):\n",
    "  def __init__(self, m=2.0):\n",
    "    super(ContrastiveLoss, self).__init__()  # pre 3.3 syntax\n",
    "    self.m = m  # margin or radius\n",
    "\n",
    "  def forward(self, y1, y2, d=0):\n",
    "    # d = 0 means y1 and y2 are supposed to be same\n",
    "    # d = 1 means y1 and y2 are supposed to be different\n",
    "    \n",
    "    euc_dist = T.nn.functional.pairwise_distance(y1, y2)\n",
    "\n",
    "    if d == 0:\n",
    "      return T.mean(T.pow(euc_dist, 2))  # distance squared\n",
    "    else:  # d == 1\n",
    "      delta = self.m - euc_dist  # sort of reverse distance\n",
    "      delta = T.clamp(delta, min=0.0, max=None)\n",
    "      return T.mean(T.pow(delta, 2))  # mean over all rows\n",
    "    \n",
    "# -----------------------------------------------------------\n",
    "\n",
    "\n",
    "# loss_func = ContrastiveLoss()\n",
    "\n",
    "\n",
    "def contrastive_loss_fn(X_train, y_train, N = 200):\n",
    "    \n",
    "    total_loss = 0\n",
    "    for i in sample(range(0, len(y_train)), N):\n",
    "        y_train_val = y_train[i]\n",
    "        x_train = X_train[i]\n",
    "\n",
    "        for j  in sample(range(0, len(y_train)), N):    \n",
    "            y_train1_val = y_train[j]        \n",
    "            x_train1 = X_train[j]    \n",
    "\n",
    "            if i != j:\n",
    "#                 print(y_train_val, y_train1_val)\n",
    "                if y_train_val == y_train1_val:\n",
    "                    loss = loss_func(x_train, x_train1, 0)\n",
    "                    total_loss += loss\n",
    "#                     print('loss1: ', loss)\n",
    "                else:\n",
    "                    loss = loss_func(x_train, x_train1, 1)\n",
    "                    total_loss += loss                    \n",
    "#                     print('loss2:', loss)\n",
    "\n",
    "    return total_loss/len(y_train)\n",
    "    \n",
    "\n",
    "def majority_classifier(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    majority_clss = Counter(y_test).most_common(1)[0][0] #np.random.choice([2,3], len(truths))\n",
    "    y_pred = [majority_clss]*len(y_test)\n",
    "        \n",
    "    return y_pred, y_test\n",
    "    \n",
    "            \n",
    "            \n",
    "def random_classifier(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    y_pred = np.random.choice(list(set(y_test)), len(y_test))\n",
    "        \n",
    "    return y_pred, y_test\n",
    "    \n",
    "    \n",
    "    \n",
    "def NN_train(X_train, y_train, X_test, y_test, contrastive_loss = False):\n",
    "    INPUT_DIM = np.asarray(X_train).shape[1] # X is 2-dimensional\n",
    "    HIDDEN_DIM = 100\n",
    "    HIDDEN_DIM2 = 20\n",
    "    NUM_CLASSES = len(set(y_train)) # 3 classes\n",
    "\n",
    "\n",
    "    # Output vectorizer\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Fit on train data\n",
    "    label_encoder = label_encoder.fit(y_train)\n",
    "    classes = list(label_encoder.classes_)\n",
    "#         print (f\"classes: {classes}\")\n",
    "\n",
    "\n",
    "    # Convert labels to tokens\n",
    "#         print (f\"y_train[0]: {y_train[0]}\")\n",
    "    y_train = label_encoder.transform(y_train)\n",
    "    # y_val = label_encoder.transform(y_val)\n",
    "    y_test = label_encoder.transform(y_test)\n",
    "#         print (f\"y_train[0]: {y_train[0]}\")\n",
    "\n",
    "\n",
    "    # Class weights\n",
    "    counts = np.bincount(y_train)\n",
    "    class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
    "#         print (f\"counts: {counts}\\nweights: {class_weights}\")\n",
    "\n",
    "\n",
    "    # Define Loss\n",
    "    class_weights_tensor = torch.Tensor(list(class_weights.values()))\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "    # Initialize model\n",
    "    model = LinearModel(input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM, hidden_dim2 = HIDDEN_DIM2, num_classes=NUM_CLASSES)\n",
    "#     print (model.named_parameters)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#     # Convert data to tensors\n",
    "    X_train = torch.Tensor(X_train)\n",
    "    y_train = torch.LongTensor(y_train)\n",
    "\n",
    "    X_val = torch.Tensor(X_test)\n",
    "    y_val = torch.LongTensor(y_test)\n",
    "    \n",
    "    fscores = []\n",
    "\n",
    "    # Training\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # Forward pass\n",
    "        z1, z2 = model(X_train)\n",
    "\n",
    "        y_pred = z2\n",
    "\n",
    "\n",
    "        loss_supervised = loss_fn(y_pred, y_train)\n",
    "    \n",
    "    \n",
    "        if contrastive_loss:\n",
    "            loss_contrastive = contrastive_loss_fn(z1, y_train, N = 50)\n",
    "            \n",
    "            loss = loss_supervised + 0.2*loss_contrastive\n",
    "        else:\n",
    "            loss = loss_supervised  #+ 0.2*loss_contrastive\n",
    "            \n",
    "            \n",
    "        # Zero all gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        best_f = 0\n",
    "        best_f_y_pred = []\n",
    "        best_f_y_test = []\n",
    "        if epoch%1==0:\n",
    "            predictions = y_pred.max(dim=1)[1] # class\n",
    "            accuracy = accuracy_fn(y_pred=predictions, y_true=y_train)\n",
    "            fscore = f1_score(predictions, y_train , average='macro')\n",
    "#             print (f\"Training -- Epoch: {epoch} | loss: {loss:.2f}, accuracy: {accuracy:.1f}, f1score: {fscore:.1f}\")\n",
    "\n",
    "            z1, z2 = model(X_val)\n",
    "            y_pred = F.softmax(z2, dim=1)\n",
    "            _, y_pred = y_pred.max(dim=1)\n",
    "            \n",
    "#             accuracy = accuracy_fn(y_pred= y_pred, y_true=y_test)\n",
    "#             fscore = f1_score(y_pred,y_test )\n",
    "\n",
    "            accuracy = accuracy_fn(y_pred=y_pred, y_true=y_val)\n",
    "            fscore = f1_score(y_pred, y_val , average='macro')\n",
    "            \n",
    "        if fscore > best_f:\n",
    "            best_f  = fscore\n",
    "            best_f_y_pred = y_pred\n",
    "            best_f_y_test = y_test\n",
    "            \n",
    "#             print ( f\" Validation -- Epoch: {epoch} | loss: {loss:.2f}, accuracy: {accuracy:.2f}, f1score: {fscore:.2f}\")        \n",
    "            \n",
    "            fscores.append(fscore)    \n",
    "            \n",
    "    \n",
    "    return best_f_y_pred, best_f_y_test\n",
    "\n",
    "\n",
    "def get_text(tweet):\n",
    "    tweetText = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", tweet) # r'(?:@[\\w_]+)'\n",
    "    tweetText = tweetText.strip().replace('rt', '').replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n",
    "    \n",
    "    return tweetText\n",
    " \n",
    "\n",
    "\n",
    "def get_statce_stats(emb, label):\n",
    "    y_counts = {}\n",
    "    y_Xs = {}\n",
    "    y_indices = {}\n",
    "    for i, (emb, label) in enumerate(zip(emb, label)):\n",
    "        if label in y_counts:\n",
    "            y_counts[label] = y_counts[label]  + 1\n",
    "        else:\n",
    "            y_counts[label] = 1    \n",
    "\n",
    "        if label in y_Xs:\n",
    "            y_Xs[label].append(emb)\n",
    "        else:\n",
    "            y_Xs[label] = [emb]  \n",
    "            \n",
    "        if label in y_indices:\n",
    "            y_indices[label].append(i)\n",
    "        else:\n",
    "            y_indices[label] = [i]  \n",
    "\n",
    "    print('lables : ', y_counts)\n",
    "    \n",
    "    return y_counts, y_Xs, y_indices\n",
    "\n",
    "def balance_stance_classes(emb_vec, labels):\n",
    "    y_counts, y_Xs, y_indices = get_statce_stats(emb_vec, labels)  \n",
    "    \n",
    "        \n",
    "    majority_label = 0\n",
    "    minority_label = 1\n",
    "    majority_count = 0\n",
    "    for key, val in y_counts.items():\n",
    "        if val > majority_count:\n",
    "            \n",
    "            minority_label = majority_label\n",
    "            majority_label = key\n",
    "            majority_count= val\n",
    "        else:\n",
    "            minority_label = key\n",
    "        \n",
    "    new_emb_vec = []    \n",
    "    new_labels = []\n",
    "    for label in y_counts.keys():\n",
    "        if label != majority_label:\n",
    "            minority_label = label\n",
    "            \n",
    "            if y_counts[majority_label] > y_counts[minority_label]:\n",
    "                additional_samples_count = y_counts[majority_label] - y_counts[minority_label]\n",
    "\n",
    "                indices = rd.choice(list(y_indices[minority_label]), size=additional_samples_count, replace=True)\n",
    "                for index in indices:\n",
    "                    new_emb_vec.append(emb_vec[index])\n",
    "                    new_labels.append(labels[index])\n",
    "            \n",
    "\n",
    "    y_counts, y_Xs, y_indices  = get_statce_stats(new_emb_vec + emb_vec, new_labels + labels)        \n",
    "    \n",
    "\n",
    "    return  new_emb_vec + emb_vec, new_labels + labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4c0563",
   "metadata": {},
   "source": [
    "## Define Sentiment Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "402f852e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    # Tokenize the text\n",
    "\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stop words\n",
    "\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "\n",
    "    # Lemmatize the tokens\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "\n",
    "    # Join the tokens back into a string\n",
    "    processed_text = ' '.join(lemmatized_tokens)\n",
    "\n",
    "    return processed_text\n",
    "\n",
    "# create get_sentiment function\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(text):\n",
    "\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "\n",
    "    sentiment = 1 if scores['pos'] > scores['neg'] else -1\n",
    "#     sentiment = -1 if scores['neg'] > 0 else 0\n",
    "    return sentiment\n",
    "\n",
    "\n",
    "def textblob_sentiment_analysis(text):\n",
    "    \n",
    "    score = TextBlob(text).sentiment.polarity\n",
    "    if score < 0:\n",
    "        return -1\n",
    "    elif score >= 0:\n",
    "        return 1\n",
    "    \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f524beb2",
   "metadata": {},
   "source": [
    "## Define Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f5f2ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifier = ('svm12', Pipeline([('vect', CountVectorizer()),\n",
    "                                             ('tfidf', TfidfTransformer()),\n",
    "                                             ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                                                       alpha=1e-3, max_iter=15, random_state=42)),\n",
    "                                            ])\n",
    "                                        , {'vect__ngram_range': [(1, 1), (1, 2)], \n",
    "                                          'tfidf__use_idf': (True, False),\n",
    "                                          'clf-svm__alpha': (1e-2, 1e-3),\n",
    "                                         })\n",
    "\n",
    "clf_name, sgd_text_clf, __  = classifier\n",
    "\n",
    "classifier = ('svm12', Pipeline([('vect', CountVectorizer()),\n",
    "                                             ('tfidf', TfidfTransformer()),\n",
    "                                             ('clf-svm', MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)),\n",
    "                                            ])\n",
    "                                        , {'vect__ngram_range': [(1, 1), (1, 2)], \n",
    "                                          'tfidf__use_idf': (True, False),\n",
    "                                          'clf-svm__alpha': (1e-2, 1e-3),\n",
    "                                         })\n",
    "\n",
    "clf_name, mlp_text_clf, __  = classifier\n",
    "\n",
    "mlp_clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
    "sgd_clf = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, max_iter=15, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee5eb4d",
   "metadata": {},
   "source": [
    "## Filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38a86ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['target_text_cleaned'] = df['target_text'].apply(preprocess_text)\n",
    "df['response_text_cleaned'] = df['response_text'].apply(preprocess_text)\n",
    "\n",
    "\n",
    "df['target_text_sentiment_vader'] = df['target_text_cleaned'].apply(get_sentiment)\n",
    "df['response_text_sentiment_vader'] = df['response_text_cleaned'].apply(get_sentiment)\n",
    "\n",
    "\n",
    "df['target_text_sentiment_textblob'] = df['target_text_cleaned'].apply(textblob_sentiment_analysis)\n",
    "df['response_text_sentiment_textbolb'] = df['response_text_cleaned'].apply(textblob_sentiment_analysis)\n",
    "df_filtered = df[df['label'] != 'Comment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ace68d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['event', 'response_id', 'target_id', 'interaction_type', 'label',\n",
      "       'label_expanded', 'Confidence_Level', 'response_text', 'target_text',\n",
      "       'truncated', 'response_text_ada_embedding', 'target_text_ada_embedding',\n",
      "       'target_user', 'response_user', 'target_user_embedding',\n",
      "       'response_user_embedding', 'target_user_embedding_8',\n",
      "       'response_user_embedding_8', 'present_in_train',\n",
      "       'np_response_text_ada_embedding', 'np_target_text_ada_embedding',\n",
      "       'np_target_user_embedding', 'np_response_user_embedding',\n",
      "       'target_text_cleaned', 'response_text_cleaned',\n",
      "       'target_text_sentiment_vader', 'response_text_sentiment_vader',\n",
      "       'target_text_sentiment_textblob', 'response_text_sentiment_textbolb'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>response_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>interaction_type</th>\n",
       "      <th>label</th>\n",
       "      <th>label_expanded</th>\n",
       "      <th>Confidence_Level</th>\n",
       "      <th>response_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>...</th>\n",
       "      <th>np_response_text_ada_embedding</th>\n",
       "      <th>np_target_text_ada_embedding</th>\n",
       "      <th>np_target_user_embedding</th>\n",
       "      <th>np_response_user_embedding</th>\n",
       "      <th>target_text_cleaned</th>\n",
       "      <th>response_text_cleaned</th>\n",
       "      <th>target_text_sentiment_vader</th>\n",
       "      <th>response_text_sentiment_vader</th>\n",
       "      <th>target_text_sentiment_textblob</th>\n",
       "      <th>response_text_sentiment_textbolb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>997626508050157568</td>\n",
       "      <td>997598447376175104</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Support</td>\n",
       "      <td>Implicit_Support</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Seriously, wtf is wrong with our political sys...</td>\n",
       "      <td>More children have been killed in schools this...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.025092221796512604, -0.013276644051074982,...</td>\n",
       "      <td>[-0.008838048204779625, -0.003347944701090455,...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>child killed school year serving military . le...</td>\n",
       "      <td>seriously , wtf wrong political system ! polit...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>997575042027458561</td>\n",
       "      <td>997573240380968961</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Denial</td>\n",
       "      <td>Explicit_Denial</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ma calls BS! https://t.co/bodEWN5Q4C</td>\n",
       "      <td>Former GOP Rep. Jason Chaffetz: 'Politically c...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.033440690487623215, 0.007639116141945124, ...</td>\n",
       "      <td>[-0.027197668328881264, 0.0034390492364764214,...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.2439490556716919, -0.44223514199256897, 0.1...</td>\n",
       "      <td>former gop rep. jason chaffetz : 'politically ...</td>\n",
       "      <td>call b ! http : //t.co/bodewn5q4c</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>997540582846271494</td>\n",
       "      <td>997535659870117888</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Denial</td>\n",
       "      <td>Explicit_Denial</td>\n",
       "      <td>1.0</td>\n",
       "      <td>On average, there’s one fake stat about school...</td>\n",
       "      <td>On average, that’s one school shooting every w...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.023548724129796028, 0.022269316017627716, ...</td>\n",
       "      <td>[-0.0044773295521736145, -0.014855715446174145...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>average , ’ one school shooting every week yea...</td>\n",
       "      <td>average , ’ one fake stat school shooting idio...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>General_Terms</td>\n",
       "      <td>1018569947817992192</td>\n",
       "      <td>1017909301040635904</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Denial</td>\n",
       "      <td>Implicit_Denial</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ONE MIGHT BE MADE UP AND NOT REAL. NOT SURE. S...</td>\n",
       "      <td>I’m so confused... - When we were attacked on ...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.004989785607904196, -0.004917326848953962, ...</td>\n",
       "      <td>[-0.013004736974835396, -0.01780531369149685, ...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>’ confused ... - attacked 9/11 , american came...</td>\n",
       "      <td>one might made real . sure . still researching...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General_Terms</td>\n",
       "      <td>1019395289575239680</td>\n",
       "      <td>1017919759474622464</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Denial</td>\n",
       "      <td>Explicit_Denial</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False, adult friendships are M-F, 9-5 https://...</td>\n",
       "      <td>Adult friendships https://t.co/Cn3r9l4pZJ</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.023379407823085785, 0.010180916637182236, -...</td>\n",
       "      <td>[0.01642121560871601, 0.0012021968141198158, 0...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>adult friendship http : //t.co/cn3r9l4pzj</td>\n",
       "      <td>false , adult friendship m-f , 9-5 http : //t....</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>998727686062297088</td>\n",
       "      <td>998641852202012672</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Support</td>\n",
       "      <td>Implicit_Support</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Obviously, this is fake news because France ha...</td>\n",
       "      <td>#LeftistTerrorism #LeftistSedition #WhineAndCh...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.012956563383340836, 0.0036507989279925823,...</td>\n",
       "      <td>[-0.029683180153369904, -0.013163618743419647,...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.08675669133663177, -0.5026119947433472, 0.2...</td>\n",
       "      <td># leftistterrorism # leftistsedition # whinean...</td>\n",
       "      <td>obviously , fake news france wall-to-wall gun ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3698</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>999033162209443841</td>\n",
       "      <td>999032790304854021</td>\n",
       "      <td>Reply</td>\n",
       "      <td>Support</td>\n",
       "      <td>Implicit_Support</td>\n",
       "      <td>2.0</td>\n",
       "      <td>@Goss30Goss There is no such thing as a Consti...</td>\n",
       "      <td>Our founding fathers did not create a country ...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.023475689813494682, 0.022063223645091057, ...</td>\n",
       "      <td>[0.0012622424401342869, 0.0014467427972704172,...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>founding father create country wannabe authori...</td>\n",
       "      <td>@ goss30goss thing constitutional conservative...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3699</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>999044683509714944</td>\n",
       "      <td>999009592867778560</td>\n",
       "      <td>Reply</td>\n",
       "      <td>Denial</td>\n",
       "      <td>Explicit_Denial</td>\n",
       "      <td>2.0</td>\n",
       "      <td>@teamtrace the trace is a @MikeBloomberg shell...</td>\n",
       "      <td>Police confronted the Santa Fe gunman four min...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.0470198318362236, -0.019923418760299683, -...</td>\n",
       "      <td>[-0.01337257120758295, 0.013017261400818825, -...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>police confronted santa fe gunman four minute ...</td>\n",
       "      <td>@ teamtrace trace @ mikebloomberg shell compan...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3700</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>999366932024393728</td>\n",
       "      <td>998952797637890048</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Denial</td>\n",
       "      <td>Implicit_Denial</td>\n",
       "      <td>2.0</td>\n",
       "      <td>This must be a tough position for the parents ...</td>\n",
       "      <td>“My son, to me, is not a criminal, he’s a vict...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.005462398752570152, -0.00494138989597559, ...</td>\n",
       "      <td>[-0.018083559349179268, 0.016592662781476974, ...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>“ son , , criminal , ’ victim. ” father santa ...</td>\n",
       "      <td>must tough position parent however , way justi...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3701</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>999759333633097728</td>\n",
       "      <td>999714805333147650</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Denial</td>\n",
       "      <td>Implicit_Denial</td>\n",
       "      <td>2.0</td>\n",
       "      <td>So violate the first amendment in fake defense...</td>\n",
       "      <td>\"It's time to put an end to this glorification...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.005952725652605295, -0.007570847403258085,...</td>\n",
       "      <td>[-0.004135181661695242, 0.021491341292858124, ...</td>\n",
       "      <td>[0.16930730640888214, -0.4844645857810974, 0.2...</td>\n",
       "      <td>[0.1620851755142212, -0.4702264964580536, 0.21...</td>\n",
       "      <td>`` 's time put end glorification carnage pursu...</td>\n",
       "      <td>violate first amendment fake defense second am...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3702 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  event          response_id            target_id  \\\n",
       "0     Santa_Fe_Shooting   997626508050157568   997598447376175104   \n",
       "1     Santa_Fe_Shooting   997575042027458561   997573240380968961   \n",
       "2     Santa_Fe_Shooting   997540582846271494   997535659870117888   \n",
       "3         General_Terms  1018569947817992192  1017909301040635904   \n",
       "4         General_Terms  1019395289575239680  1017919759474622464   \n",
       "...                 ...                  ...                  ...   \n",
       "3697  Santa_Fe_Shooting   998727686062297088   998641852202012672   \n",
       "3698  Santa_Fe_Shooting   999033162209443841   999032790304854021   \n",
       "3699  Santa_Fe_Shooting   999044683509714944   999009592867778560   \n",
       "3700  Santa_Fe_Shooting   999366932024393728   998952797637890048   \n",
       "3701  Santa_Fe_Shooting   999759333633097728   999714805333147650   \n",
       "\n",
       "     interaction_type    label    label_expanded Confidence_Level  \\\n",
       "0               Quote  Support  Implicit_Support              1.0   \n",
       "1               Quote   Denial   Explicit_Denial              1.0   \n",
       "2               Quote   Denial   Explicit_Denial              1.0   \n",
       "3               Quote   Denial   Implicit_Denial              1.0   \n",
       "4               Quote   Denial   Explicit_Denial              1.0   \n",
       "...               ...      ...               ...              ...   \n",
       "3697            Quote  Support  Implicit_Support              2.0   \n",
       "3698            Reply  Support  Implicit_Support              2.0   \n",
       "3699            Reply   Denial   Explicit_Denial              2.0   \n",
       "3700            Quote   Denial   Implicit_Denial              2.0   \n",
       "3701            Quote   Denial   Implicit_Denial              2.0   \n",
       "\n",
       "                                          response_text  \\\n",
       "0     Seriously, wtf is wrong with our political sys...   \n",
       "1                  Ma calls BS! https://t.co/bodEWN5Q4C   \n",
       "2     On average, there’s one fake stat about school...   \n",
       "3     ONE MIGHT BE MADE UP AND NOT REAL. NOT SURE. S...   \n",
       "4     False, adult friendships are M-F, 9-5 https://...   \n",
       "...                                                 ...   \n",
       "3697  Obviously, this is fake news because France ha...   \n",
       "3698  @Goss30Goss There is no such thing as a Consti...   \n",
       "3699  @teamtrace the trace is a @MikeBloomberg shell...   \n",
       "3700  This must be a tough position for the parents ...   \n",
       "3701  So violate the first amendment in fake defense...   \n",
       "\n",
       "                                            target_text  truncated  ...  \\\n",
       "0     More children have been killed in schools this...      False  ...   \n",
       "1     Former GOP Rep. Jason Chaffetz: 'Politically c...      False  ...   \n",
       "2     On average, that’s one school shooting every w...      False  ...   \n",
       "3     I’m so confused... - When we were attacked on ...      False  ...   \n",
       "4             Adult friendships https://t.co/Cn3r9l4pZJ      False  ...   \n",
       "...                                                 ...        ...  ...   \n",
       "3697  #LeftistTerrorism #LeftistSedition #WhineAndCh...      False  ...   \n",
       "3698  Our founding fathers did not create a country ...      False  ...   \n",
       "3699  Police confronted the Santa Fe gunman four min...      False  ...   \n",
       "3700  “My son, to me, is not a criminal, he’s a vict...      False  ...   \n",
       "3701  \"It's time to put an end to this glorification...      False  ...   \n",
       "\n",
       "                         np_response_text_ada_embedding  \\\n",
       "0     [-0.025092221796512604, -0.013276644051074982,...   \n",
       "1     [-0.033440690487623215, 0.007639116141945124, ...   \n",
       "2     [-0.023548724129796028, 0.022269316017627716, ...   \n",
       "3     [0.004989785607904196, -0.004917326848953962, ...   \n",
       "4     [0.023379407823085785, 0.010180916637182236, -...   \n",
       "...                                                 ...   \n",
       "3697  [-0.012956563383340836, 0.0036507989279925823,...   \n",
       "3698  [-0.023475689813494682, 0.022063223645091057, ...   \n",
       "3699  [-0.0470198318362236, -0.019923418760299683, -...   \n",
       "3700  [-0.005462398752570152, -0.00494138989597559, ...   \n",
       "3701  [-0.005952725652605295, -0.007570847403258085,...   \n",
       "\n",
       "                           np_target_text_ada_embedding  \\\n",
       "0     [-0.008838048204779625, -0.003347944701090455,...   \n",
       "1     [-0.027197668328881264, 0.0034390492364764214,...   \n",
       "2     [-0.0044773295521736145, -0.014855715446174145...   \n",
       "3     [-0.013004736974835396, -0.01780531369149685, ...   \n",
       "4     [0.01642121560871601, 0.0012021968141198158, 0...   \n",
       "...                                                 ...   \n",
       "3697  [-0.029683180153369904, -0.013163618743419647,...   \n",
       "3698  [0.0012622424401342869, 0.0014467427972704172,...   \n",
       "3699  [-0.01337257120758295, 0.013017261400818825, -...   \n",
       "3700  [-0.018083559349179268, 0.016592662781476974, ...   \n",
       "3701  [-0.004135181661695242, 0.021491341292858124, ...   \n",
       "\n",
       "                               np_target_user_embedding  \\\n",
       "0     [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "1     [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "2     [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "3     [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "4     [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "...                                                 ...   \n",
       "3697  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "3698  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "3699  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "3700  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "3701  [0.16930730640888214, -0.4844645857810974, 0.2...   \n",
       "\n",
       "                             np_response_user_embedding  \\\n",
       "0     [0.1620851755142212, -0.4702264964580536, 0.21...   \n",
       "1     [0.2439490556716919, -0.44223514199256897, 0.1...   \n",
       "2     [0.1620851755142212, -0.4702264964580536, 0.21...   \n",
       "3     [0.1620851755142212, -0.4702264964580536, 0.21...   \n",
       "4     [0.1620851755142212, -0.4702264964580536, 0.21...   \n",
       "...                                                 ...   \n",
       "3697  [0.08675669133663177, -0.5026119947433472, 0.2...   \n",
       "3698  [0.1620851755142212, -0.4702264964580536, 0.21...   \n",
       "3699  [0.1620851755142212, -0.4702264964580536, 0.21...   \n",
       "3700  [0.1620851755142212, -0.4702264964580536, 0.21...   \n",
       "3701  [0.1620851755142212, -0.4702264964580536, 0.21...   \n",
       "\n",
       "                                    target_text_cleaned  \\\n",
       "0     child killed school year serving military . le...   \n",
       "1     former gop rep. jason chaffetz : 'politically ...   \n",
       "2     average , ’ one school shooting every week yea...   \n",
       "3     ’ confused ... - attacked 9/11 , american came...   \n",
       "4             adult friendship http : //t.co/cn3r9l4pzj   \n",
       "...                                                 ...   \n",
       "3697  # leftistterrorism # leftistsedition # whinean...   \n",
       "3698  founding father create country wannabe authori...   \n",
       "3699  police confronted santa fe gunman four minute ...   \n",
       "3700  “ son , , criminal , ’ victim. ” father santa ...   \n",
       "3701  `` 's time put end glorification carnage pursu...   \n",
       "\n",
       "                                  response_text_cleaned  \\\n",
       "0     seriously , wtf wrong political system ! polit...   \n",
       "1                     call b ! http : //t.co/bodewn5q4c   \n",
       "2     average , ’ one fake stat school shooting idio...   \n",
       "3     one might made real . sure . still researching...   \n",
       "4     false , adult friendship m-f , 9-5 http : //t....   \n",
       "...                                                 ...   \n",
       "3697  obviously , fake news france wall-to-wall gun ...   \n",
       "3698  @ goss30goss thing constitutional conservative...   \n",
       "3699  @ teamtrace trace @ mikebloomberg shell compan...   \n",
       "3700  must tough position parent however , way justi...   \n",
       "3701  violate first amendment fake defense second am...   \n",
       "\n",
       "     target_text_sentiment_vader response_text_sentiment_vader  \\\n",
       "0                             -1                            -1   \n",
       "1                             -1                            -1   \n",
       "2                             -1                            -1   \n",
       "3                             -1                             1   \n",
       "4                              1                             1   \n",
       "...                          ...                           ...   \n",
       "3697                          -1                            -1   \n",
       "3698                          -1                            -1   \n",
       "3699                          -1                            -1   \n",
       "3700                          -1                            -1   \n",
       "3701                          -1                            -1   \n",
       "\n",
       "     target_text_sentiment_textblob response_text_sentiment_textbolb  \n",
       "0                                -1                               -1  \n",
       "1                                 1                                1  \n",
       "2                                 1                               -1  \n",
       "3                                -1                                1  \n",
       "4                                 1                               -1  \n",
       "...                             ...                              ...  \n",
       "3697                              1                               -1  \n",
       "3698                             -1                               -1  \n",
       "3699                              1                                1  \n",
       "3700                             -1                               -1  \n",
       "3701                             -1                               -1  \n",
       "\n",
       "[3702 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Visualize data\n",
    "\n",
    "print(df_filtered.columns)\n",
    "\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea37b4a",
   "metadata": {},
   "source": [
    "## Event wise evaluation of algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64b3391e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iran_Deal\n",
      "646 646 277 277\n",
      "Random Classifier - fscore:  0.4583072590738423\n",
      "Majority Classifier - fscore:  0.3436018957345972\n",
      "Vader Sentiment Classifier - fscore:  0.4658134642356241\n",
      "TextBlob Sentiment Classifier - fscore:  0.5483597469510207\n",
      "SVM Text  Model - fscore:  0.0\n",
      "MLP Text  Model - fscore:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding + MLP Model - fscore:  0.7472100542344597\n",
      "Text Embedding + MLP Model - fscore:  0.764113246603519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/var/folders/c4/z6xs643x2dlf5_h1t65gjzc00000gp/T/ipykernel_33336/2833463865.py:162: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  X_train = torch.Tensor(X_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.714563360073045\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7251984126984127\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.7292418772563177\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.7328206465067779\n",
      "646 646 277 277\n",
      "Random Classifier - fscore:  0.46795499980400607\n",
      "Majority Classifier - fscore:  0.3357314148681055\n",
      "Vader Sentiment Classifier - fscore:  0.4863472291032628\n",
      "TextBlob Sentiment Classifier - fscore:  0.5128871391076115\n",
      "SVM Text  Model - fscore:  0.0\n",
      "MLP Text  Model - fscore:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding + MLP Model - fscore:  0.7472627737226277\n",
      "Text Embedding + MLP Model - fscore:  0.7031082529474812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.7430258842590778\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7397975159169189\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.7544838373305527\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.7576679506430763\n",
      "646 646 277 277\n",
      "Random Classifier - fscore:  0.5085064189541801\n",
      "Majority Classifier - fscore:  0.3466981132075472\n",
      "Vader Sentiment Classifier - fscore:  0.4172510518934081\n",
      "TextBlob Sentiment Classifier - fscore:  0.537851929092805\n",
      "SVM Text  Model - fscore:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Text  Model - fscore:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding + MLP Model - fscore:  0.7324300334168755\n",
      "Text Embedding + MLP Model - fscore:  0.7455380577427821\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7066023302342004\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.6964304352364055\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.7500686516809856\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.7460978420280745\n",
      "646 646 277 277\n",
      "Random Classifier - fscore:  0.5414923427826654\n",
      "Majority Classifier - fscore:  0.33890214797136037\n",
      "Vader Sentiment Classifier - fscore:  0.45798802946593\n",
      "TextBlob Sentiment Classifier - fscore:  0.49777603860953495\n",
      "SVM Text  Model - fscore:  0.0\n",
      "MLP Text  Model - fscore:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding + MLP Model - fscore:  0.7036582820164909\n",
      "Text Embedding + MLP Model - fscore:  0.7170804525455687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.6724219489120151\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.6748869166150153\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.7250261233019855\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.7362420922193962\n",
      "646 646 277 277\n",
      "Random Classifier - fscore:  0.5516395154553049\n",
      "Majority Classifier - fscore:  0.351288056206089\n",
      "Vader Sentiment Classifier - fscore:  0.47630863759896025\n",
      "TextBlob Sentiment Classifier - fscore:  0.5592853416797079\n",
      "SVM Text  Model - fscore:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Text  Model - fscore:  0.0\n",
      "Text Embedding + MLP Model - fscore:  0.7253418223567476\n",
      "Text Embedding + MLP Model - fscore:  0.7539707419017763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.7219636828177753\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7219636828177753\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.732262277951933\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.7544838373305527\n",
      "646 646 277 277\n",
      "Random Classifier - fscore:  0.5434065934065935\n",
      "Majority Classifier - fscore:  0.3543123543123543\n",
      "Vader Sentiment Classifier - fscore:  0.462518329803149\n",
      "TextBlob Sentiment Classifier - fscore:  0.5449780976220275\n",
      "SVM Text  Model - fscore:  0.3543123543123543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Text  Model - fscore:  0.3543123543123543\n",
      "Text Embedding + MLP Model - fscore:  0.7753270538984824\n",
      "Text Embedding + MLP Model - fscore:  0.7748794043624161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.7544326241134751\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.768079539508111\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.8013508403635273\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.8013508403635273\n",
      "646 646 277 277\n",
      "Random Classifier - fscore:  0.5071690214547357\n",
      "Majority Classifier - fscore:  0.3436018957345972\n",
      "Vader Sentiment Classifier - fscore:  0.49768441022207344\n",
      "TextBlob Sentiment Classifier - fscore:  0.5289115646258503\n",
      "SVM Text  Model - fscore:  0.32273838630806845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Text  Model - fscore:  0.32273838630806845\n",
      "Text Embedding + MLP Model - fscore:  0.6668932343406881\n",
      "Text Embedding + MLP Model - fscore:  0.6509423624808239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.6893322900365154\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.6930767927209209\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.6893322900365154\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.707565982404692\n",
      "646 646 277 277\n",
      "Random Classifier - fscore:  0.5269771746640075\n",
      "Majority Classifier - fscore:  0.3341346153846154\n",
      "Vader Sentiment Classifier - fscore:  0.536885302529949\n",
      "TextBlob Sentiment Classifier - fscore:  0.5399814313548572\n",
      "SVM Text  Model - fscore:  0.3325301204819277\n",
      "MLP Text  Model - fscore:  0.3325301204819277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding + MLP Model - fscore:  0.7470253626970045\n",
      "Text Embedding + MLP Model - fscore:  0.7544326241134751\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7147419602935616\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7147419602935617\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.7761470281543275\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.7650367354395856\n",
      "646 646 277 277\n",
      "Random Classifier - fscore:  0.5376108502869066\n",
      "Majority Classifier - fscore:  0.3482352941176471\n",
      "Vader Sentiment Classifier - fscore:  0.47851605758582505\n",
      "TextBlob Sentiment Classifier - fscore:  0.5889722007012199\n",
      "SVM Text  Model - fscore:  0.31773399014778325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Text  Model - fscore:  0.31773399014778325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding + MLP Model - fscore:  0.7615805946791863\n",
      "Text Embedding + MLP Model - fscore:  0.7535845107273679\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7035035505430243\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7394984326018809\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.7430258842590778\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.7470253626970045\n",
      "646 646 277 277\n",
      "Random Classifier - fscore:  0.5374178060745225\n",
      "Majority Classifier - fscore:  0.3558139534883721\n",
      "Vader Sentiment Classifier - fscore:  0.4863022992838296\n",
      "TextBlob Sentiment Classifier - fscore:  0.5558640647608619\n",
      "SVM Text  Model - fscore:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Text  Model - fscore:  0.0\n",
      "Text Embedding + MLP Model - fscore:  0.7322622779519332\n",
      "Text Embedding + MLP Model - fscore:  0.7002203590940501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.7216589019822783\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7019160104986877\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.6850608143839239\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.7109437949937256\n",
      "Iran_Deal  Random based:  0.5180481981956764\n",
      "Iran_Deal  Majority based:  0.34523197410252854\n",
      "Iran_Deal  Vader Sentiment based:  0.47656148117220115\n",
      "Iran_Deal  Textblob Sentiment based:  0.5414867554505498\n",
      "Iran_Deal  SVM Text based:  0.13273148512501337\n",
      "Iran_Deal  MLP Text based:  0.13273148512501337\n",
      "Iran_Deal  Text Emdedding MLP based:  0.7317870012519261\n",
      "Iran_Deal  Text Embeddings SGD based:  0.7338991489314496\n",
      "Iran_Deal  Text Embeddings NN based:  0.7142246533264969\n",
      "Iran_Deal  Text + Node embedding based:  0.7175589698907691\n",
      "Iran_Deal  Text + Stance emdedding based:  0.7385999624719146\n",
      "Iran_Deal  Text + Node + Stance based:  0.7459235084626412\n",
      "Student_Marches\n",
      "397 397 171 171\n",
      "Random Classifier - fscore:  0.5140215716486902\n",
      "Majority Classifier - fscore:  0.3346303501945525\n",
      "Vader Sentiment Classifier - fscore:  0.4436289346246973\n",
      "TextBlob Sentiment Classifier - fscore:  0.46196990424076606\n",
      "SVM Text  Model - fscore:  1.0\n",
      "MLP Text  Model - fscore:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding + MLP Model - fscore:  0.7426108374384235\n",
      "Text Embedding + MLP Model - fscore:  0.7768543956043956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.7777701778385773\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7355397463656046\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.8067796610169492\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.7833590138674884\n",
      "397 397 171 171\n",
      "Random Classifier - fscore:  0.5026518391787853\n",
      "Majority Classifier - fscore:  0.35714285714285715\n",
      "Vader Sentiment Classifier - fscore:  0.4710121192269898\n",
      "TextBlob Sentiment Classifier - fscore:  0.5079473828446149\n",
      "SVM Text  Model - fscore:  0.30769230769230765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Text  Model - fscore:  0.30769230769230765\n",
      "Text Embedding + MLP Model - fscore:  0.7597079891695515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding + MLP Model - fscore:  0.712821743153854\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7939404372525392\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7878411910669976\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.7799840038947038\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.8123456790123457\n",
      "397 397 171 171\n",
      "Random Classifier - fscore:  0.4962318443409154\n",
      "Majority Classifier - fscore:  0.3473282442748092\n",
      "Vader Sentiment Classifier - fscore:  0.48684210526315785\n",
      "TextBlob Sentiment Classifier - fscore:  0.43150426705967027\n",
      "SVM Text  Model - fscore:  0.3473282442748092\n",
      "MLP Text  Model - fscore:  0.3473282442748092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding + MLP Model - fscore:  0.7498606854276957\n",
      "Text Embedding + MLP Model - fscore:  0.6857598557608959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.7498606854276957\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7519342359767892\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.7785051636618239\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.8048552754435108\n",
      "397 397 171 171\n",
      "Random Classifier - fscore:  0.4887101763068358\n",
      "Majority Classifier - fscore:  0.3643122676579926\n",
      "Vader Sentiment Classifier - fscore:  0.48155293932354215\n",
      "TextBlob Sentiment Classifier - fscore:  0.4671052631578947\n",
      "SVM Text  Model - fscore:  0.3643122676579926\n",
      "MLP Text  Model - fscore:  0.3643122676579926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding + MLP Model - fscore:  0.747112676056338\n",
      "Text Embedding + MLP Model - fscore:  0.7537037037037035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.7750000000000001\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7912087912087913\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.8144232452301767\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.8087783058428851\n",
      "397 397 171 171\n",
      "Random Classifier - fscore:  0.5782406138668128\n",
      "Majority Classifier - fscore:  0.3666666666666667\n",
      "Vader Sentiment Classifier - fscore:  0.4941637352094659\n",
      "TextBlob Sentiment Classifier - fscore:  0.45494739006751894\n",
      "SVM Text  Model - fscore:  0.3666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Text  Model - fscore:  0.3666666666666667\n",
      "Text Embedding + MLP Model - fscore:  0.7046836142580823\n",
      "Text Embedding + MLP Model - fscore:  0.6865857454092748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.7506249999999999\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.701713582104867\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.7873722022658193\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.798125\n",
      "397 397 171 171\n",
      "Random Classifier - fscore:  0.48451630583721567\n",
      "Majority Classifier - fscore:  0.3448275862068966\n",
      "Vader Sentiment Classifier - fscore:  0.48575498575498577\n",
      "TextBlob Sentiment Classifier - fscore:  0.48522167487684725\n",
      "SVM Text  Model - fscore:  0.3448275862068966\n",
      "MLP Text  Model - fscore:  0.3448275862068966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding + MLP Model - fscore:  0.7680912473484716\n",
      "Text Embedding + MLP Model - fscore:  0.7597079891695515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.7463170605485596\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7774047684297067\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.7825549025672749\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.7986842105263159\n",
      "397 397 171 171\n",
      "Random Classifier - fscore:  0.4969211822660099\n",
      "Majority Classifier - fscore:  0.33976833976833976\n",
      "Vader Sentiment Classifier - fscore:  0.5365853658536587\n",
      "TextBlob Sentiment Classifier - fscore:  0.47953216374269003\n",
      "SVM Text  Model - fscore:  0.33976833976833976\n",
      "MLP Text  Model - fscore:  0.33976833976833976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding + MLP Model - fscore:  0.7601026518391787\n",
      "Text Embedding + MLP Model - fscore:  0.7597079891695513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.32677165354330706\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.747986427665627\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.7833590138674884\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.7599383667180277\n",
      "397 397 171 171\n",
      "Random Classifier - fscore:  0.5437192118226601\n",
      "Majority Classifier - fscore:  0.3423076923076923\n",
      "Vader Sentiment Classifier - fscore:  0.4824455205811138\n",
      "TextBlob Sentiment Classifier - fscore:  0.4552631578947368\n",
      "SVM Text  Model - fscore:  0.3423076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Text  Model - fscore:  0.3423076923076923\n",
      "Text Embedding + MLP Model - fscore:  0.7888888888888888\n",
      "Text Embedding + MLP Model - fscore:  0.7176664832140891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.7656892299260072\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7825549025672749\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.7541757940854326\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.7774047684297067\n",
      "397 397 171 171\n",
      "Random Classifier - fscore:  0.45494739006751894\n",
      "Majority Classifier - fscore:  0.3522727272727273\n",
      "Vader Sentiment Classifier - fscore:  0.5308188739034664\n",
      "TextBlob Sentiment Classifier - fscore:  0.4735221674876847\n",
      "SVM Text  Model - fscore:  0.3522727272727273\n",
      "MLP Text  Model - fscore:  0.3522727272727273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding + MLP Model - fscore:  0.7855948732237392\n",
      "Text Embedding + MLP Model - fscore:  0.7597079891695514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.7912087912087912\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7882498624105669\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.8053130929791272\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.798125\n",
      "397 397 171 171\n",
      "Random Classifier - fscore:  0.49115846359065574\n",
      "Majority Classifier - fscore:  0.3595505617977528\n",
      "Vader Sentiment Classifier - fscore:  0.5308188739034665\n",
      "TextBlob Sentiment Classifier - fscore:  0.4470968629609246\n",
      "SVM Text  Model - fscore:  0.3595505617977528\n",
      "MLP Text  Model - fscore:  0.3595505617977528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding + MLP Model - fscore:  0.7365177195685669\n",
      "Text Embedding + MLP Model - fscore:  0.7368061018572356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.7124669709344222\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7120321682647694\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.7298763736263736\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.7362648661617026\n",
      "Student_Marches  Random based:  0.5051118598926101\n",
      "Student_Marches  Majority based:  0.3508807293290287\n",
      "Student_Marches  Vader Sentiment based:  0.49436234536445445\n",
      "Student_Marches  Textblob Sentiment based:  0.46641102343333485\n",
      "Student_Marches  SVM Text based:  0.4124726393645185\n",
      "Student_Marches  MLP Text based:  0.4124726393645185\n",
      "Student_Marches  Text Emdedding MLP based:  0.7349321996212103\n",
      "Student_Marches  Text Embeddings SGD based:  0.7543171183218936\n",
      "Student_Marches  Text Embeddings NN based:  0.71896500066799\n",
      "Student_Marches  Text + Node embedding based:  0.7576465676060995\n",
      "Student_Marches  Text + Stance emdedding based:  0.782234345319517\n",
      "Student_Marches  Text + Node + Stance based:  0.7877880486001982\n",
      "Santa_Fe_Shooting\n",
      "678 678 291 291\n",
      "Random Classifier - fscore:  0.5240981240981242\n",
      "Majority Classifier - fscore:  0.3834745762711864\n",
      "Vader Sentiment Classifier - fscore:  0.5038611974726708\n",
      "TextBlob Sentiment Classifier - fscore:  0.482555644122877\n",
      "SVM Text  Model - fscore:  0.3834745762711864\n",
      "MLP Text  Model - fscore:  0.3834745762711864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding + MLP Model - fscore:  0.7625701172870984\n",
      "Text Embedding + MLP Model - fscore:  0.6909515717926933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.7328913819479856\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7579645125516685\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.7863188405797101\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.7988479262672811\n",
      "678 678 291 291\n",
      "Random Classifier - fscore:  0.49174562159058277\n",
      "Majority Classifier - fscore:  0.37820512820512814\n",
      "Vader Sentiment Classifier - fscore:  0.46513595518730305\n",
      "TextBlob Sentiment Classifier - fscore:  0.5382910434203355\n",
      "SVM Text  Model - fscore:  0.37820512820512814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Text  Model - fscore:  0.37820512820512814\n",
      "Text Embedding + MLP Model - fscore:  0.7822725458898643\n",
      "Text Embedding + MLP Model - fscore:  0.6109924555553848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.7620428189116861\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7645191409897292\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.8136453201970444\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.8156432748538012\n",
      "678 678 291 291\n",
      "Random Classifier - fscore:  0.463067674543182\n",
      "Majority Classifier - fscore:  0.38993710691823896\n",
      "Vader Sentiment Classifier - fscore:  0.4504041701291833\n",
      "TextBlob Sentiment Classifier - fscore:  0.4868227686881551\n",
      "SVM Text  Model - fscore:  0.38993710691823896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Text  Model - fscore:  0.38993710691823896\n",
      "Text Embedding + MLP Model - fscore:  0.7881095029445204\n",
      "Text Embedding + MLP Model - fscore:  0.736563750714694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.7757532067216864\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7726333299727794\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.8037711363029123\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.8004399301287443\n",
      "678 678 291 291\n",
      "Random Classifier - fscore:  0.5033122068249364\n",
      "Majority Classifier - fscore:  0.3847780126849894\n",
      "Vader Sentiment Classifier - fscore:  0.4788457956645701\n",
      "TextBlob Sentiment Classifier - fscore:  0.49106585947532566\n",
      "SVM Text  Model - fscore:  0.3847780126849894\n",
      "MLP Text  Model - fscore:  0.3847780126849894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding + MLP Model - fscore:  0.7680738379267791\n",
      "Text Embedding + MLP Model - fscore:  0.673591370753369\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7811235605353252\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7512820512820513\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.7675624450010153\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.7754416841535234\n",
      "678 678 291 291\n",
      "Random Classifier - fscore:  0.48866203664965274\n",
      "Majority Classifier - fscore:  0.37820512820512814\n",
      "Vader Sentiment Classifier - fscore:  0.4635743724241289\n",
      "TextBlob Sentiment Classifier - fscore:  0.45811357929766816\n",
      "SVM Text  Model - fscore:  0.37820512820512814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Text  Model - fscore:  0.37820512820512814\n",
      "Text Embedding + MLP Model - fscore:  0.7782704822813746\n",
      "Text Embedding + MLP Model - fscore:  0.7788212560386474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.7652788980579512\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7693875240575117\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.8313043478260871\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.8125185845970859\n",
      "678 678 291 291\n",
      "Random Classifier - fscore:  0.5087578569290632\n",
      "Majority Classifier - fscore:  0.3834745762711864\n",
      "Vader Sentiment Classifier - fscore:  0.49194141836808314\n",
      "TextBlob Sentiment Classifier - fscore:  0.47599250710012697\n",
      "SVM Text  Model - fscore:  0.3834745762711864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Text  Model - fscore:  0.3834745762711864\n",
      "Text Embedding + MLP Model - fscore:  0.7409947643979057\n",
      "Text Embedding + MLP Model - fscore:  0.7465848681388669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.7328913819479856\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7200379696499353\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.8126254655640426\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.8028660760812923\n",
      "678 678 291 291\n",
      "Random Classifier - fscore:  0.4369087434304826\n",
      "Majority Classifier - fscore:  0.39375000000000004\n",
      "Vader Sentiment Classifier - fscore:  0.5031653697967817\n",
      "TextBlob Sentiment Classifier - fscore:  0.5092871329177961\n",
      "SVM Text  Model - fscore:  0.39375000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Text  Model - fscore:  0.39375000000000004\n",
      "Text Embedding + MLP Model - fscore:  0.7900074786464961\n",
      "Text Embedding + MLP Model - fscore:  0.6583683118637526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.774599358974359\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7692787605443414\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.812962772521596\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.795284002084419\n",
      "678 678 291 291\n",
      "Random Classifier - fscore:  0.43960515957124685\n",
      "Majority Classifier - fscore:  0.3860759493670886\n",
      "Vader Sentiment Classifier - fscore:  0.4538303938564695\n",
      "TextBlob Sentiment Classifier - fscore:  0.5408915795266923\n",
      "SVM Text  Model - fscore:  0.3860759493670886\n",
      "MLP Text  Model - fscore:  0.3860759493670886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding + MLP Model - fscore:  0.8059926789690177\n",
      "Text Embedding + MLP Model - fscore:  0.7998821102269378\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7882487882487883\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7755553270259152\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.7930719219829339\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.7953792064289302\n",
      "678 678 291 291\n",
      "Random Classifier - fscore:  0.5613695090439277\n",
      "Majority Classifier - fscore:  0.37553648068669526\n",
      "Vader Sentiment Classifier - fscore:  0.5023672569498424\n",
      "TextBlob Sentiment Classifier - fscore:  0.48910533910533915\n",
      "SVM Text  Model - fscore:  0.37553648068669526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Text  Model - fscore:  0.37553648068669526\n",
      "Text Embedding + MLP Model - fscore:  0.7941676490662034\n",
      "Text Embedding + MLP Model - fscore:  0.7685373398144056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.7829869742467933\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.784029586022114\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.8222835645886262\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.7971381397908641\n",
      "678 678 291 291\n",
      "Random Classifier - fscore:  0.48394363496932513\n",
      "Majority Classifier - fscore:  0.3860759493670886\n",
      "Vader Sentiment Classifier - fscore:  0.4722967403521918\n",
      "TextBlob Sentiment Classifier - fscore:  0.4825556441228769\n",
      "SVM Text  Model - fscore:  0.3860759493670886\n",
      "MLP Text  Model - fscore:  0.3860759493670886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding + MLP Model - fscore:  0.7806747486618719\n",
      "Text Embedding + MLP Model - fscore:  0.670855850194797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings + User Graph Embeddings - fscore:  0.7655746509129968\n",
      "Text Embeddings + User Graph Embeddings - fscore:  0.7815565479598459\n",
      "Text Embeddings + User Opinion Embeddings - fscore:  0.8078524989841529\n",
      "fText Embeddings + User Graph + Opinion Embeddings -  score:  0.7913978494623656\n",
      "Santa_Fe_Shooting  Random based:  0.4901470567650524\n",
      "Santa_Fe_Shooting  Majority based:  0.383951290797673\n",
      "Santa_Fe_Shooting  Vader Sentiment based:  0.4785422670201225\n",
      "Santa_Fe_Shooting  Textblob Sentiment based:  0.4954681097777193\n",
      "Santa_Fe_Shooting  SVM Text based:  0.383951290797673\n",
      "Santa_Fe_Shooting  MLP Text based:  0.383951290797673\n",
      "Santa_Fe_Shooting  Text Emdedding MLP based:  0.7135148885093547\n",
      "Santa_Fe_Shooting  Text Embeddings SGD based:  0.7791133806071132\n",
      "Santa_Fe_Shooting  Text Embeddings NN based:  0.7661391020505558\n",
      "Santa_Fe_Shooting  Text + Node embedding based:  0.7646244750055892\n",
      "Santa_Fe_Shooting  Text + Stance emdedding based:  0.8051398313548122\n",
      "Santa_Fe_Shooting  Text + Node + Stance based:  0.7984956673848306\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_embedding_label = []\n",
    "test_embedding_label = []\n",
    "train_count = 0\n",
    "test_count = 0\n",
    "\n",
    "\n",
    "stance_embedding_size = 8\n",
    "event_fscores = {}\n",
    "\n",
    "for event in { 'Iran_Deal', 'Santa_Fe_Shooting', 'Student_Marches'}:        \n",
    "    \n",
    "    stance_df = pd.read_csv('./data/' + event + '_userstances.csv', encoding=\"utf-8\", \n",
    "                 dtype={\"response_user\":str, \"target_user\":str} ).fillna('')\n",
    "\n",
    "        \n",
    "    df_event = df_filtered[df_filtered['event'] == event] #  & \n",
    "    \n",
    "    df_event = df_event.merge(stance_df, how='left', on=['target_user', 'response_user'])\n",
    "    \n",
    "\n",
    "    \n",
    "    f_scores_random = []    \n",
    "    f_scores_majority = [] \n",
    "    f_scores_vader = []\n",
    "    f_scores_textblob = []\n",
    "    f_scores_mlp = []\n",
    "    f_scores_sgd = []\n",
    "\n",
    "\n",
    "    f_scores_mlp_embeddings = []\n",
    "    f_scores_sgd_embeddings = []\n",
    "    f_scores_nn_embeddings = []\n",
    "    \n",
    "    f_scores_node_embedding = []\n",
    "    f_scores_stance_embedding = []\n",
    "    f_scores_node_stance_embedding = []\n",
    "\n",
    "    \n",
    "    print(event) \n",
    "    \n",
    "    for iteration in range(0, 10):\n",
    "    \n",
    "        df_event_train, df_event_test = train_test_split(df_event, test_size=0.3)\n",
    "\n",
    "#         print(event, len(df_event_train), len(df_event_test))\n",
    "\n",
    "        X_train = []\n",
    "        X_test = []    \n",
    "\n",
    "        X_train_node_embedding = []\n",
    "        X_test_node_embedding = []    \n",
    "\n",
    "        X_train_stance_embedding = []\n",
    "        X_test_stance_embedding = []    \n",
    "\n",
    "\n",
    "        X_train_node_stance_embedding = []\n",
    "        X_test_node_stance_embedding = []    \n",
    "\n",
    "\n",
    "        y_train = []    \n",
    "        y_test = []\n",
    "\n",
    "        vader_sentiment_test = []\n",
    "        blob_sentiment_test = []        \n",
    "        y_test_sentiment = []\n",
    "        y_train_sentiment = []\n",
    "        \n",
    "\n",
    "        train_replies = []\n",
    "        test_replies = []        \n",
    "#         print(len(df_event_train))\n",
    "        \n",
    "        \n",
    "        for idx, train_row in df_event_train.iterrows():\n",
    "                        \n",
    "            target_node = train_row['target_user']\n",
    "            response_node = train_row['response_user']\n",
    "            response_embedding = train_row['np_response_text_ada_embedding']\n",
    "            target_embedding = train_row['np_target_text_ada_embedding']\n",
    "            target_user_embeddings = train_row['np_target_user_embedding']\n",
    "            response_user_embeddings = train_row['np_response_user_embedding']\n",
    "            target_user_stance = train_row['target_user_stance']\n",
    "            response_user_stance = train_row['response_user_stance']\n",
    "            label = train_row['label']   \n",
    "            train_replies.append(train_row['response_text_cleaned'])\n",
    "\n",
    "            embedding = np.concatenate([response_embedding , target_embedding ], axis = 0)                \n",
    "            X_train.append(embedding)\n",
    "\n",
    "            embedding = np.concatenate([response_embedding , target_embedding, target_user_embeddings, response_user_embeddings ], axis = 0) \n",
    "            X_train_node_embedding.append(embedding)            \n",
    "\n",
    "            embedding = np.concatenate([response_embedding , target_embedding, np.asarray(stance_embedding_size*[target_user_stance]), np.asarray(stance_embedding_size*[response_user_stance]) ], axis = 0) \n",
    "            X_train_stance_embedding.append(embedding)            \n",
    "\n",
    "            embedding = np.concatenate([response_embedding , target_embedding, target_user_embeddings, response_user_embeddings, np.asarray(stance_embedding_size*[target_user_stance]), np.asarray(stance_embedding_size*[response_user_stance]) ], axis = 0) \n",
    "            X_train_node_stance_embedding.append(embedding)            \n",
    "\n",
    "            y_train.append(label)\n",
    "            \n",
    "            if label == 'Support':\n",
    "                y_train_sentiment.append(1)\n",
    "\n",
    "            elif label == 'Denial':\n",
    "                y_train_sentiment.append(-1)\n",
    "            else:\n",
    "                y_train_sentiment.append(0)\n",
    "            \n",
    "\n",
    "            train_count += 1\n",
    "            \n",
    "\n",
    "        for idx, test_row in df_event_test.iterrows():\n",
    "\n",
    "            target_node = test_row['target_user']\n",
    "            response_node = test_row['response_user']\n",
    "            response_embedding = test_row['np_response_text_ada_embedding']\n",
    "            target_embedding = test_row['np_target_text_ada_embedding']\n",
    "            target_user_embeddings = test_row['np_target_user_embedding']\n",
    "            response_user_embeddings = test_row['np_response_user_embedding']\n",
    "            target_user_stance= test_row['target_user_stance']\n",
    "            response_user_stance = test_row['response_user_stance']\n",
    "            label = test_row['label']\n",
    "            test_replies.append(test_row['response_text_cleaned'])            \n",
    "\n",
    "\n",
    "            embedding = np.concatenate([response_embedding , target_embedding ], axis = 0)                \n",
    "            X_test.append(embedding)\n",
    "\n",
    "            embedding = np.concatenate([response_embedding , target_embedding, target_user_embeddings, response_user_embeddings ], axis = 0) \n",
    "            X_test_node_embedding.append(embedding)            \n",
    "\n",
    "            embedding = np.concatenate([response_embedding , target_embedding, np.asarray(stance_embedding_size*[target_user_stance]), np.asarray(stance_embedding_size*[response_user_stance]) ], axis = 0) \n",
    "            X_test_stance_embedding.append(embedding)            \n",
    "\n",
    "            embedding = np.concatenate([response_embedding , target_embedding, target_user_embeddings, response_user_embeddings, np.asarray(stance_embedding_size*[target_user_stance]), np.asarray(stance_embedding_size*[response_user_stance]) ], axis = 0) \n",
    "            X_test_node_stance_embedding.append(embedding)  \n",
    "\n",
    "            y_test.append(label)\n",
    "            \n",
    "            if label == 'Support':\n",
    "                y_test_sentiment.append(1)\n",
    "\n",
    "            elif label == 'Denial':\n",
    "                y_test_sentiment.append(-1)\n",
    "            else:\n",
    "                y_test_sentiment.append(0)\n",
    "\n",
    "            \n",
    "            vader_sentiment_test.append( test_row['response_text_sentiment_vader'])\n",
    "            blob_sentiment_test.append( test_row['response_text_sentiment_textbolb'])\n",
    "            \n",
    "\n",
    "            test_count += 1    \n",
    "\n",
    "\n",
    "        print(len(X_train), len(y_train), len(X_test), len(y_test))\n",
    "        \n",
    "        ## 1. Random classifier\n",
    "        \n",
    "        preds, y_test_out = random_classifier(X_train, y_train, X_test, y_test)\n",
    "        fscore = f1_score(preds, y_test_out , average='macro')\n",
    "        print('Random Classifier - fscore: ', fscore)    \n",
    "        f_scores_random.append(fscore)\n",
    "        \n",
    "        ## 2. Majority classifier      \n",
    "        \n",
    "        preds, y_test_out = majority_classifier(X_train, y_train, X_test, y_test)\n",
    "        fscore = f1_score(preds, y_test_out , average='macro')\n",
    "        print('Majority Classifier - fscore: ', fscore)    \n",
    "        f_scores_majority.append(fscore)\n",
    "        \n",
    "        ## 3. Vader classifier                \n",
    "        \n",
    "        fscore = f1_score(vader_sentiment_test, y_test_sentiment , average='macro')\n",
    "        print('Vader Sentiment Classifier - fscore: ', fscore)    \n",
    "        f_scores_vader.append(fscore)\n",
    "\n",
    "        \n",
    "        \n",
    "        ## 4. TextBlob classifier\n",
    "        \n",
    "        fscore = f1_score(blob_sentiment_test, y_test_sentiment , average='macro')\n",
    "        print('TextBlob Sentiment Classifier - fscore: ', fscore)    \n",
    "        f_scores_textblob.append(fscore)        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ## 5. Baseline Supervised Classifiers\n",
    "        \n",
    "        sgd_text_clf.fit(train_replies,  y_train)\n",
    "\n",
    "        preds = sgd_text_clf.predict(y_test)\n",
    "        fscore = f1_score(preds, y_test , average='macro')\n",
    "        print('SVM Text  Model - fscore: ', fscore)\n",
    "        f_scores_sgd.append(fscore)\n",
    "        \n",
    "        \n",
    "        mlp_text_clf.fit(train_replies,  y_train)\n",
    "\n",
    "        preds = sgd_text_clf.predict(y_test)\n",
    "        fscore = f1_score(preds, y_test , average='macro')\n",
    "        print('MLP Text  Model - fscore: ', fscore)\n",
    "        f_scores_mlp.append(fscore)\n",
    "        \n",
    "                \n",
    "        \n",
    "        ## 6. Open AI GPT - Text Embedding Models\n",
    "\n",
    "    \n",
    "        mlp_clf.fit(X_train, y_train)\n",
    "        preds = mlp_clf.predict(X_test)\n",
    "        fscore = f1_score(preds, y_test , average='macro')\n",
    "        print('Text Embedding + MLP Model - fscore: ', fscore)\n",
    "        f_scores_sgd_embeddings.append(fscore)\n",
    "        \n",
    "        \n",
    "        sgd_clf.fit(X_train, y_train)\n",
    "        preds = sgd_clf.predict(X_test)        \n",
    "        fscore = f1_score(preds, y_test , average='macro')\n",
    "        print('Text Embedding + MLP Model - fscore: ', fscore)\n",
    "        f_scores_mlp_embeddings.append(fscore)        \n",
    "    \n",
    "    \n",
    "        preds, y_test_out = NN_train(X_train, y_train, X_test, y_test)\n",
    "        fscore = f1_score(preds, y_test_out , average='macro')\n",
    "        print('Text Embeddings + User Graph Embeddings - fscore: ', fscore)\n",
    "        f_scores_nn_embeddings.append(fscore)\n",
    "        \n",
    "        ## 7. Open AI GPT Text Embeddings + User Embeddings        \n",
    "\n",
    "        preds, y_test_out = NN_train(X_train_node_embedding, y_train, X_test_node_embedding, y_test)\n",
    "        fscore = f1_score(preds, y_test_out , average='macro')\n",
    "        print('Text Embeddings + User Graph Embeddings - fscore: ', fscore)\n",
    "        f_scores_node_embedding.append(fscore)\n",
    "\n",
    "        preds, y_test_out = NN_train(X_train_stance_embedding, y_train, X_test_stance_embedding, y_test)    \n",
    "        fscore = f1_score(preds, y_test_out , average='macro')\n",
    "        print('Text Embeddings + User Opinion Embeddings - fscore: ', fscore)\n",
    "        f_scores_stance_embedding.append(fscore)\n",
    "\n",
    "\n",
    "        preds, y_test_out = NN_train(X_train_node_stance_embedding, y_train, X_test_node_stance_embedding, y_test)\n",
    "        fscore = f1_score(preds, y_test_out , average='macro')\n",
    "        print('fText Embeddings + User Graph + Opinion Embeddings -  score: ', fscore)\n",
    "        f_scores_node_stance_embedding.append(fscore)\n",
    "\n",
    "    print(event, ' Random based: ', np.mean(f_scores_random))          \n",
    "    print(event, ' Majority based: ', np.mean(f_scores_majority))      \n",
    "    print(event, ' Vader Sentiment based: ', np.mean(f_scores_vader))      \n",
    "    print(event, ' Textblob Sentiment based: ', np.mean(f_scores_textblob))      \n",
    "    print(event, ' SVM Text based: ', np.mean(f_scores_sgd))          \n",
    "    print(event, ' MLP Text based: ', np.mean(f_scores_mlp))     \n",
    "    print(event, ' Text Emdedding MLP based: ', np.mean(f_scores_mlp_embeddings))     \n",
    "    print(event, ' Text Embeddings SGD based: ', np.mean(f_scores_sgd_embeddings))         \n",
    "    print(event, ' Text Embeddings NN based: ', np.mean(f_scores_nn_embeddings))             \n",
    "\n",
    "    print(event, ' Text + Node embedding based: ', np.mean(f_scores_node_embedding))      \n",
    "    print(event, ' Text + Stance emdedding based: ', np.mean(f_scores_stance_embedding))      \n",
    "    print(event, ' Text + Node + Stance based: ', np.mean(f_scores_node_stance_embedding))  \n",
    "    \n",
    "    event_fscores[event] = {'f_scores_random': f_scores_random, \n",
    "                            'f_scores_majority': f_scores_majority, \n",
    "                            'f_scores_vader': f_scores_vader,\n",
    "                            'f_scores_textblob': f_scores_textblob,\n",
    "                            'f_scores_sgd': f_scores_sgd, \n",
    "                            'f_scores_mlp':f_scores_mlp, \n",
    "                            'f_scores_mlp_embeddings': f_scores_mlp_embeddings,\n",
    "                            'f_scores_sgd_embeddings': f_scores_sgd_embeddings, \n",
    "                            'f_scores_nn_embeddings': f_scores_nn_embeddings,\n",
    "                            'f_scores_node_embedding': f_scores_node_embedding, \n",
    "                            'f_scores_stance_embedding': f_scores_stance_embedding, \n",
    "                            'f_scores_node_stance_embedding': f_scores_node_stance_embedding}\n",
    "    \n",
    "    \n",
    "    \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8de9c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "\n",
    "with open('./data/event_fscores_2_class.pkl', 'wb') as f:\n",
    "    pickle.dump(event_fscores, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f924f872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_scores_random&0.51&0.49&0.52&0.50\n",
      "f_scores_majority&0.35&0.38&0.35&0.36\n",
      "f_scores_vader&0.49&0.48&0.48&0.48\n",
      "f_scores_textblob&0.47&0.50&0.54&0.50\n",
      "f_scores_sgd&0.41&0.38&0.13&0.31\n",
      "f_scores_mlp&0.41&0.38&0.13&0.31\n",
      "f_scores_mlp_embeddings&0.73&0.71&0.73&0.73\n",
      "f_scores_sgd_embeddings&0.75&0.78&0.73&0.76\n",
      "f_scores_nn_embeddings&0.72&0.77&0.71&0.73\n",
      "f_scores_node_embedding&0.76&0.76&0.72&0.75\n",
      "f_scores_stance_embedding&0.78&0.81&0.74&0.78\n",
      "f_scores_node_stance_embedding&0.79&0.80&0.75&0.78\n"
     ]
    }
   ],
   "source": [
    "## Put results in a format for the paper\n",
    "\n",
    "for result_type in ['f_scores_random', \n",
    "                    'f_scores_majority', \n",
    "                    'f_scores_vader',\n",
    "                    'f_scores_textblob',\n",
    "                    'f_scores_sgd', \n",
    "                    'f_scores_mlp', \n",
    "                    'f_scores_mlp_embeddings',\n",
    "                    'f_scores_sgd_embeddings', \n",
    "                    'f_scores_nn_embeddings',\n",
    "                    'f_scores_node_embedding', \n",
    "                    'f_scores_stance_embedding', \n",
    "                    'f_scores_node_stance_embedding']:\n",
    "\n",
    "\n",
    "    print(\"{}&{:.2f}&{:.2f}&{:.2f}&{:.2f}\".format(result_type,\n",
    "                                                  np.mean(event_fscores['Student_Marches'][result_type]),\n",
    "                                                np.mean(event_fscores['Santa_Fe_Shooting'][result_type]), \n",
    "                                                np.mean(event_fscores['Iran_Deal'][result_type]),\n",
    "                                                np.mean([np.mean(event_fscores['Student_Marches'][result_type]),\n",
    "                                                         np.mean(event_fscores['Santa_Fe_Shooting'][result_type]), \n",
    "                                                         np.mean(event_fscores['Iran_Deal'][result_type])])\n",
    "                                              ))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a61400a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
