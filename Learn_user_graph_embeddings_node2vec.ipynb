{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29e6a915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1536,)\n",
      "3702\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>response_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>interaction_type</th>\n",
       "      <th>label</th>\n",
       "      <th>label_expanded</th>\n",
       "      <th>Confidence_Level</th>\n",
       "      <th>response_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>response_text_ada_embedding</th>\n",
       "      <th>target_text_ada_embedding</th>\n",
       "      <th>np_target_text_ada_embedding</th>\n",
       "      <th>np_response_text_ada_embedding</th>\n",
       "      <th>target_user</th>\n",
       "      <th>response_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>997626508050157568</td>\n",
       "      <td>997598447376175104</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Support</td>\n",
       "      <td>Implicit_Support</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Seriously, wtf is wrong with our political sys...</td>\n",
       "      <td>More children have been killed in schools this...</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.025092221796512604, -0.013276644051074982,...</td>\n",
       "      <td>[-0.008838048204779625, -0.003347944701090455,...</td>\n",
       "      <td>[-0.008838048204779625, -0.003347944701090455,...</td>\n",
       "      <td>[-0.025092221796512604, -0.013276644051074982,...</td>\n",
       "      <td>321631653</td>\n",
       "      <td>18655355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>997575042027458561</td>\n",
       "      <td>997573240380968961</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Denial</td>\n",
       "      <td>Explicit_Denial</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ma calls BS! https://t.co/bodEWN5Q4C</td>\n",
       "      <td>Former GOP Rep. Jason Chaffetz: 'Politically c...</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.033440690487623215, 0.007639116141945124, ...</td>\n",
       "      <td>[-0.027197668328881264, 0.0034390492364764214,...</td>\n",
       "      <td>[-0.027197668328881264, 0.0034390492364764214,...</td>\n",
       "      <td>[-0.033440690487623215, 0.007639116141945124, ...</td>\n",
       "      <td>2467720274</td>\n",
       "      <td>3176702526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>997540582846271494</td>\n",
       "      <td>997535659870117888</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Denial</td>\n",
       "      <td>Explicit_Denial</td>\n",
       "      <td>1.0</td>\n",
       "      <td>On average, there’s one fake stat about school...</td>\n",
       "      <td>On average, that’s one school shooting every w...</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.023548724129796028, 0.022269316017627716, ...</td>\n",
       "      <td>[-0.0044773295521736145, -0.014855715446174145...</td>\n",
       "      <td>[-0.0044773295521736145, -0.014855715446174145...</td>\n",
       "      <td>[-0.023548724129796028, 0.022269316017627716, ...</td>\n",
       "      <td>24939978</td>\n",
       "      <td>1646856415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>General_Terms</td>\n",
       "      <td>1018569947817992192</td>\n",
       "      <td>1017909301040635904</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Denial</td>\n",
       "      <td>Implicit_Denial</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ONE MIGHT BE MADE UP AND NOT REAL. NOT SURE. S...</td>\n",
       "      <td>I’m so confused... - When we were attacked on ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.004989785607904196, -0.004917326848953962, ...</td>\n",
       "      <td>[-0.013004736974835396, -0.01780531369149685, ...</td>\n",
       "      <td>[-0.013004736974835396, -0.01780531369149685, ...</td>\n",
       "      <td>[0.004989785607904196, -0.004917326848953962, ...</td>\n",
       "      <td>2932942216</td>\n",
       "      <td>766475610059317248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General_Terms</td>\n",
       "      <td>1019395289575239680</td>\n",
       "      <td>1017919759474622464</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Denial</td>\n",
       "      <td>Explicit_Denial</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False, adult friendships are M-F, 9-5 https://...</td>\n",
       "      <td>Adult friendships https://t.co/Cn3r9l4pZJ</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.023379407823085785, 0.010180916637182236, -...</td>\n",
       "      <td>[0.01642121560871601, 0.0012021968141198158, 0...</td>\n",
       "      <td>[0.01642121560871601, 0.0012021968141198158, 0...</td>\n",
       "      <td>[0.023379407823085785, 0.010180916637182236, -...</td>\n",
       "      <td>2909998207</td>\n",
       "      <td>59621769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>998727686062297088</td>\n",
       "      <td>998641852202012672</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Support</td>\n",
       "      <td>Implicit_Support</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Obviously, this is fake news because France ha...</td>\n",
       "      <td>#LeftistTerrorism #LeftistSedition #WhineAndCh...</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.012956563383340836, 0.0036507989279925823,...</td>\n",
       "      <td>[-0.029683180153369904, -0.013163618743419647,...</td>\n",
       "      <td>[-0.029683180153369904, -0.013163618743419647,...</td>\n",
       "      <td>[-0.012956563383340836, 0.0036507989279925823,...</td>\n",
       "      <td>899115298997055491</td>\n",
       "      <td>23194229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3698</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>999033162209443841</td>\n",
       "      <td>999032790304854021</td>\n",
       "      <td>Reply</td>\n",
       "      <td>Support</td>\n",
       "      <td>Implicit_Support</td>\n",
       "      <td>2.0</td>\n",
       "      <td>@Goss30Goss There is no such thing as a Consti...</td>\n",
       "      <td>Our founding fathers did not create a country ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.023475689813494682, 0.022063223645091057, ...</td>\n",
       "      <td>[0.0012622424401342869, 0.0014467427972704172,...</td>\n",
       "      <td>[0.0012622424401342869, 0.0014467427972704172,...</td>\n",
       "      <td>[-0.023475689813494682, 0.022063223645091057, ...</td>\n",
       "      <td>2869858477</td>\n",
       "      <td>807692474684579840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3699</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>999044683509714944</td>\n",
       "      <td>999009592867778560</td>\n",
       "      <td>Reply</td>\n",
       "      <td>Denial</td>\n",
       "      <td>Explicit_Denial</td>\n",
       "      <td>2.0</td>\n",
       "      <td>@teamtrace the trace is a @MikeBloomberg shell...</td>\n",
       "      <td>Police confronted the Santa Fe gunman four min...</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.0470198318362236, -0.019923418760299683, -...</td>\n",
       "      <td>[-0.01337257120758295, 0.013017261400818825, -...</td>\n",
       "      <td>[-0.01337257120758295, 0.013017261400818825, -...</td>\n",
       "      <td>[-0.0470198318362236, -0.019923418760299683, -...</td>\n",
       "      <td>3243500510</td>\n",
       "      <td>994750018300018688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3700</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>999366932024393728</td>\n",
       "      <td>998952797637890048</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Denial</td>\n",
       "      <td>Implicit_Denial</td>\n",
       "      <td>2.0</td>\n",
       "      <td>This must be a tough position for the parents ...</td>\n",
       "      <td>“My son, to me, is not a criminal, he’s a vict...</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.005462398752570152, -0.00494138989597559, ...</td>\n",
       "      <td>[-0.018083559349179268, 0.016592662781476974, ...</td>\n",
       "      <td>[-0.018083559349179268, 0.016592662781476974, ...</td>\n",
       "      <td>[-0.005462398752570152, -0.00494138989597559, ...</td>\n",
       "      <td>424385350</td>\n",
       "      <td>59213861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3701</th>\n",
       "      <td>Santa_Fe_Shooting</td>\n",
       "      <td>999759333633097728</td>\n",
       "      <td>999714805333147650</td>\n",
       "      <td>Quote</td>\n",
       "      <td>Denial</td>\n",
       "      <td>Implicit_Denial</td>\n",
       "      <td>2.0</td>\n",
       "      <td>So violate the first amendment in fake defense...</td>\n",
       "      <td>\"It's time to put an end to this glorification...</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.005952725652605295, -0.007570847403258085,...</td>\n",
       "      <td>[-0.004135181661695242, 0.021491341292858124, ...</td>\n",
       "      <td>[-0.004135181661695242, 0.021491341292858124, ...</td>\n",
       "      <td>[-0.005952725652605295, -0.007570847403258085,...</td>\n",
       "      <td>17564591</td>\n",
       "      <td>26589498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3702 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  event          response_id            target_id  \\\n",
       "0     Santa_Fe_Shooting   997626508050157568   997598447376175104   \n",
       "1     Santa_Fe_Shooting   997575042027458561   997573240380968961   \n",
       "2     Santa_Fe_Shooting   997540582846271494   997535659870117888   \n",
       "3         General_Terms  1018569947817992192  1017909301040635904   \n",
       "4         General_Terms  1019395289575239680  1017919759474622464   \n",
       "...                 ...                  ...                  ...   \n",
       "3697  Santa_Fe_Shooting   998727686062297088   998641852202012672   \n",
       "3698  Santa_Fe_Shooting   999033162209443841   999032790304854021   \n",
       "3699  Santa_Fe_Shooting   999044683509714944   999009592867778560   \n",
       "3700  Santa_Fe_Shooting   999366932024393728   998952797637890048   \n",
       "3701  Santa_Fe_Shooting   999759333633097728   999714805333147650   \n",
       "\n",
       "     interaction_type    label    label_expanded  Confidence_Level  \\\n",
       "0               Quote  Support  Implicit_Support               1.0   \n",
       "1               Quote   Denial   Explicit_Denial               1.0   \n",
       "2               Quote   Denial   Explicit_Denial               1.0   \n",
       "3               Quote   Denial   Implicit_Denial               1.0   \n",
       "4               Quote   Denial   Explicit_Denial               1.0   \n",
       "...               ...      ...               ...               ...   \n",
       "3697            Quote  Support  Implicit_Support               2.0   \n",
       "3698            Reply  Support  Implicit_Support               2.0   \n",
       "3699            Reply   Denial   Explicit_Denial               2.0   \n",
       "3700            Quote   Denial   Implicit_Denial               2.0   \n",
       "3701            Quote   Denial   Implicit_Denial               2.0   \n",
       "\n",
       "                                          response_text  \\\n",
       "0     Seriously, wtf is wrong with our political sys...   \n",
       "1                  Ma calls BS! https://t.co/bodEWN5Q4C   \n",
       "2     On average, there’s one fake stat about school...   \n",
       "3     ONE MIGHT BE MADE UP AND NOT REAL. NOT SURE. S...   \n",
       "4     False, adult friendships are M-F, 9-5 https://...   \n",
       "...                                                 ...   \n",
       "3697  Obviously, this is fake news because France ha...   \n",
       "3698  @Goss30Goss There is no such thing as a Consti...   \n",
       "3699  @teamtrace the trace is a @MikeBloomberg shell...   \n",
       "3700  This must be a tough position for the parents ...   \n",
       "3701  So violate the first amendment in fake defense...   \n",
       "\n",
       "                                            target_text  truncated  \\\n",
       "0     More children have been killed in schools this...      False   \n",
       "1     Former GOP Rep. Jason Chaffetz: 'Politically c...      False   \n",
       "2     On average, that’s one school shooting every w...      False   \n",
       "3     I’m so confused... - When we were attacked on ...      False   \n",
       "4             Adult friendships https://t.co/Cn3r9l4pZJ      False   \n",
       "...                                                 ...        ...   \n",
       "3697  #LeftistTerrorism #LeftistSedition #WhineAndCh...      False   \n",
       "3698  Our founding fathers did not create a country ...      False   \n",
       "3699  Police confronted the Santa Fe gunman four min...      False   \n",
       "3700  “My son, to me, is not a criminal, he’s a vict...      False   \n",
       "3701  \"It's time to put an end to this glorification...      False   \n",
       "\n",
       "                            response_text_ada_embedding  \\\n",
       "0     [-0.025092221796512604, -0.013276644051074982,...   \n",
       "1     [-0.033440690487623215, 0.007639116141945124, ...   \n",
       "2     [-0.023548724129796028, 0.022269316017627716, ...   \n",
       "3     [0.004989785607904196, -0.004917326848953962, ...   \n",
       "4     [0.023379407823085785, 0.010180916637182236, -...   \n",
       "...                                                 ...   \n",
       "3697  [-0.012956563383340836, 0.0036507989279925823,...   \n",
       "3698  [-0.023475689813494682, 0.022063223645091057, ...   \n",
       "3699  [-0.0470198318362236, -0.019923418760299683, -...   \n",
       "3700  [-0.005462398752570152, -0.00494138989597559, ...   \n",
       "3701  [-0.005952725652605295, -0.007570847403258085,...   \n",
       "\n",
       "                              target_text_ada_embedding  \\\n",
       "0     [-0.008838048204779625, -0.003347944701090455,...   \n",
       "1     [-0.027197668328881264, 0.0034390492364764214,...   \n",
       "2     [-0.0044773295521736145, -0.014855715446174145...   \n",
       "3     [-0.013004736974835396, -0.01780531369149685, ...   \n",
       "4     [0.01642121560871601, 0.0012021968141198158, 0...   \n",
       "...                                                 ...   \n",
       "3697  [-0.029683180153369904, -0.013163618743419647,...   \n",
       "3698  [0.0012622424401342869, 0.0014467427972704172,...   \n",
       "3699  [-0.01337257120758295, 0.013017261400818825, -...   \n",
       "3700  [-0.018083559349179268, 0.016592662781476974, ...   \n",
       "3701  [-0.004135181661695242, 0.021491341292858124, ...   \n",
       "\n",
       "                           np_target_text_ada_embedding  \\\n",
       "0     [-0.008838048204779625, -0.003347944701090455,...   \n",
       "1     [-0.027197668328881264, 0.0034390492364764214,...   \n",
       "2     [-0.0044773295521736145, -0.014855715446174145...   \n",
       "3     [-0.013004736974835396, -0.01780531369149685, ...   \n",
       "4     [0.01642121560871601, 0.0012021968141198158, 0...   \n",
       "...                                                 ...   \n",
       "3697  [-0.029683180153369904, -0.013163618743419647,...   \n",
       "3698  [0.0012622424401342869, 0.0014467427972704172,...   \n",
       "3699  [-0.01337257120758295, 0.013017261400818825, -...   \n",
       "3700  [-0.018083559349179268, 0.016592662781476974, ...   \n",
       "3701  [-0.004135181661695242, 0.021491341292858124, ...   \n",
       "\n",
       "                         np_response_text_ada_embedding         target_user  \\\n",
       "0     [-0.025092221796512604, -0.013276644051074982,...           321631653   \n",
       "1     [-0.033440690487623215, 0.007639116141945124, ...          2467720274   \n",
       "2     [-0.023548724129796028, 0.022269316017627716, ...            24939978   \n",
       "3     [0.004989785607904196, -0.004917326848953962, ...          2932942216   \n",
       "4     [0.023379407823085785, 0.010180916637182236, -...          2909998207   \n",
       "...                                                 ...                 ...   \n",
       "3697  [-0.012956563383340836, 0.0036507989279925823,...  899115298997055491   \n",
       "3698  [-0.023475689813494682, 0.022063223645091057, ...          2869858477   \n",
       "3699  [-0.0470198318362236, -0.019923418760299683, -...          3243500510   \n",
       "3700  [-0.005462398752570152, -0.00494138989597559, ...           424385350   \n",
       "3701  [-0.005952725652605295, -0.007570847403258085,...            17564591   \n",
       "\n",
       "           response_user  \n",
       "0               18655355  \n",
       "1             3176702526  \n",
       "2             1646856415  \n",
       "3     766475610059317248  \n",
       "4               59621769  \n",
       "...                  ...  \n",
       "3697            23194229  \n",
       "3698  807692474684579840  \n",
       "3699  994750018300018688  \n",
       "3700            59213861  \n",
       "3701            26589498  \n",
       "\n",
       "[3702 rows x 16 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "## use predicted_user_stance to get data for users in stance in conversations dataset\n",
    "# predicted_user_stance\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./data/Contentious_pairs_with_GPT_ADA_embeddings.csv\")\n",
    "\n",
    "df['np_target_text_ada_embedding'] = df['target_text_ada_embedding'].apply(eval).apply(np.array)\n",
    "df['np_response_text_ada_embedding'] = df['response_text_ada_embedding'].apply(eval).apply(np.array)\n",
    "\n",
    "print(np.shape(df['np_target_text_ada_embedding'][0]))\n",
    "print(len(df['response_id']))\n",
    "\n",
    "with open('./data/tweetid_to_users_v2.json', 'r') as f:\n",
    "    tweetid_to_users = json.load(f)\n",
    "\n",
    "    \n",
    "df['target_user'] = df['target_id'].apply(lambda target_id: tweetid_to_users[str(target_id)] if str(target_id) in tweetid_to_users else None)\n",
    "df['response_user'] = df['response_id'].apply(lambda target_id: tweetid_to_users[str(target_id)] if str(target_id) in tweetid_to_users else None)\n",
    "\n",
    "\n",
    "df    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03662010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'defendthesecond': 1,\n",
       " '2ashallnotbeinfringed': 1,\n",
       " 'guncontrolnow': -1,\n",
       " 'gunreformnow': -1,\n",
       " 'marchforourlives': -1,\n",
       " '2adefenders': 1,\n",
       " '2ndamendment': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stance_processor.extract_data_tables import *\n",
    "from stance_processor.data_extractor import *\n",
    "from stance_processor.data_loader import *\n",
    "from stance_processor.cotraining_steps import *\n",
    "from stance_processor.ConversationsTextSVMClassifier import *\n",
    "# from stance_processor.ConversationsTextNeuralNetworkClassifier import *\n",
    "\n",
    "event_seed_tag_labels= { 'Iran_Deal':('../stance_dataset/contentious_data/', \n",
    "      { 'thankyoutrump':-1 , 'iranuprising': 1, 'freeiran': 1}, \n",
    "      'labeled_users/Iran_Deal_labels_combined.txt' ),\n",
    "\n",
    "      'Student_Marches':('../stance_dataset/contentious_data/', \n",
    "      { 'defendthesecond' : 1, '2ashallnotbeinfringed': 1,'guncontrolnow':-1, 'gunreformnow': -1,\n",
    "                          'guncontrolnow': -1,  'marchforourlives': -1,'2adefenders': 1, '2ndamendment': 1}, \n",
    "      'labeled_users/Student_Marches_labels_combined.txt' ),\n",
    "\n",
    "      'Santa_Fe_Shooting':('../stance_dataset/contentious_data/', \n",
    "      { 'defendthesecond' : 1, '2ashallnotbeinfringed': 1,'guncontrolnow':-1, 'gunreformnow': -1,\n",
    "                          'guncontrolnow': -1,  'marchforourlives': -1,'2adefenders': 1, '2ndamendment': 1})\n",
    "    }\n",
    "        \n",
    "        \n",
    "event_name = 'Student_Marches'\n",
    "# tweets_path = '../stance_dataset/rawdata/fauci_raw/'  # not needed if data extraction is not required\n",
    "results_path = './results/'\n",
    "extracted_files_path = '/Users/sumeet_kumar/Library/CloudStorage/OneDrive-IndianSchoolofBusiness/Research_projects/Stance/Stance/stance_dataset/contentious_data/'\n",
    "\n",
    "seed_tag_labels = { 'defendthesecond' : 1, '2ashallnotbeinfringed': 1,'guncontrolnow':-1, 'gunreformnow': -1,\n",
    "                   'guncontrolnow': -1,  'marchforourlives': -1,'2adefenders': 1, '2ndamendment': 1}\n",
    "\n",
    "label_file_name = '/Users/sumeet_kumar/Library/CloudStorage/OneDrive-IndianSchoolofBusiness/Research_projects/Stance/Stance/stance_dataset/labeled_users/' + event_name  + '_labels_combined.txt' #If not, leave blank\n",
    "\n",
    "\n",
    "seed_tag_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c472f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'defendthesecond': 1, '2ashallnotbeinfringed': 1, 'guncontrolnow': -1, 'gunreformnow': -1, 'marchforourlives': -1, '2adefenders': 1, '2ndamendment': 1}\n",
      "error endtag count\n",
      "error user count\n",
      "error endtag count\n",
      "error source_tweet_user count\n",
      "error retweet_user count\n",
      "error source_user count\n",
      "error source_user count\n",
      "error reply_user count\n",
      "user_tweet_count:  55813\n",
      "user_retweet_count:   4382\n",
      "user_endtag_count:  52375\n",
      "endtag_count:  17821\n",
      "user_endtag_count examples:  ['user', '1001572752', '2496463412', '823245747818733568', '2819902607', '3214757596', '41628696', '3267456386', '887442796268978176', '959797135158935553', '939899077927620614', '827373737112641537', '112296882', '73408582', '29519474', '795099402926956544', '968250635299602432', '1385420359', '15410674', '17633850']\n",
      "user_retweet_count exampless:  ['source_tweet_user', '60912576', '317385247', '604940737', '289342771', '14216661', '14435027', '3250141399', '874636442290577410', '14629315', '5988062', '202952121', '30726383', '1367531', '964032914626359296', '468646961', '17364806', '180107694', '16076032', '25073877']\n",
      "user_replies_count exampless:  ['reply_user', '3652916954', '791077327', '829914268246093824', '422894799', '4447793901', '18082945', '874636442290577410', '890387589299134465', '351120282', '843571300098625537', '3995778614', '69190453', '60912576', '2335542810', '17364806', '839300788702875649', '867947619661881344', '92580421', '16155881']\n",
      "users_text:  402985\n",
      "endtags_text:  2781\n",
      "hashtag_text:  5827\n",
      "user_url_count:  135862\n",
      "media_fullurls_weighted data issue\n",
      "user_media_url_count:  0\n",
      "reply_data count 597712\n",
      "{'defendthesecond': 1, '2ashallnotbeinfringed': 1, 'guncontrolnow': -1, 'gunreformnow': -1, 'marchforourlives': -1, '2adefenders': 1, '2ndamendment': 1} /Users/sumeet_kumar/Library/CloudStorage/OneDrive-IndianSchoolofBusiness/Research_projects/Stance/Stance/stance_dataset/labeled_users/Student_Marches_labels_combined.txt Student_Marches\n",
      "<stance_processor.data_extractor.Data object at 0x13aea0ee0>\n",
      "{'defendthesecond': 1, '2ashallnotbeinfringed': 1, 'guncontrolnow': -1, 'gunreformnow': -1, 'marchforourlives': -1, '2adefenders': 1, '2ndamendment': 1}\n",
      "error endtag count\n",
      "error user count\n",
      "error endtag count\n",
      "error source_tweet_user count\n",
      "error retweet_user count\n",
      "error source_user count\n",
      "error source_user count\n",
      "error reply_user count\n",
      "user_tweet_count:  151235\n",
      "user_retweet_count:   2781\n",
      "user_endtag_count:  149364\n",
      "endtag_count:  45057\n",
      "user_endtag_count examples:  ['user', '4852311119', '1942377590', '18022791', '887588053', '390140934', '780626889916321792', '141457038', '872806967093473282', '960196633089646592', '41628696', '4034705230', '385688415', '871149485715365888', '457521902', '2392801119', '1060074588', '887442796268978176', '959797135158935553', '45218857']\n",
      "user_retweet_count exampless:  ['source_tweet_user', '53692193', '1317129865', '855007514621911040', '878087280321335298', '25073877', '727264708776980480', '3493563087', '292929271', '810619093749559296', '17564591', '26642006', '38029205', '807095', '6473022', '187428929', '17261066', '14247236', '964032914626359296', '149249831']\n",
      "user_replies_count exampless:  ['reply_user', '348631421', '601535938', '36429938', '826550703258791937', '253316481', '958064770019741696', '824797212425191425', '7702542', '18510860', '3493563087', '491461409', '894465693755637760', '3448405037', '4698979873', '166751745', '920455609056559105', '246939630', '751766718', '35281339']\n",
      "users_text:  997957\n",
      "endtags_text:  7441\n",
      "hashtag_text:  15664\n",
      "user_url_count:  169544\n",
      "media_fullurls_weighted data issue\n",
      "user_media_url_count:  0\n",
      "reply_data count 731977\n",
      "{'defendthesecond': 1, '2ashallnotbeinfringed': 1, 'guncontrolnow': -1, 'gunreformnow': -1, 'marchforourlives': -1, '2adefenders': 1, '2ndamendment': 1} /Users/sumeet_kumar/Library/CloudStorage/OneDrive-IndianSchoolofBusiness/Research_projects/Stance/Stance/stance_dataset/labeled_users/Santa_Fe_Shooting_labels_combined.txt Santa_Fe_Shooting\n",
      "<stance_processor.data_extractor.Data object at 0x13aeb3040>\n",
      "{'thankyoutrump': -1, 'iranuprising': 1, 'freeiran': 1}\n",
      "error endtag count\n",
      "error user count\n",
      "error endtag count\n",
      "error source_tweet_user count\n",
      "error retweet_user count\n",
      "error source_user count\n",
      "error source_user count\n",
      "error reply_user count\n",
      "user_tweet_count:  235765\n",
      "user_retweet_count:   5727\n",
      "user_endtag_count:  233289\n",
      "endtag_count:  86653\n",
      "user_endtag_count examples:  ['user', '1001572752', '748682921817628672', '48323667', '881590861569576960', '18022791', '2496463412', '1643956716', '1316686338', '872806967093473282', '2421055130', '41628696', '3310943306', '718245694168047617', '322584847', '840845019770576896', '2650519274', '8698812', '887442796268978176', '28538480']\n",
      "user_retweet_count exampless:  ['source_tweet_user', '553991829', '25073877', '592730371', '1652541', '970207298', '40996128', '247981000', '51241574', '54412900', '759251', '114870265', '2180371', '469194846', '78523300', '17061263', '160010755', '132339474', '27995424', '25320639']\n",
      "user_replies_count exampless:  ['reply_user', '187796215', '55113967', '940430173517811714', '422894799', '2869858477', '946940097756385281', '1375289149', '17801749', '432895323', '2686106365', '2554131522', '15063486', '4281570916', '54065567', '34240147', '978787610', '475454826', '880818095786524673', '477864155']\n",
      "users_text:  634793\n",
      "endtags_text:  12153\n",
      "hashtag_text:  25320\n",
      "user_url_count:  250927\n",
      "media_fullurls_weighted data issue\n",
      "user_media_url_count:  0\n",
      "reply_data count 569426\n",
      "{'thankyoutrump': -1, 'iranuprising': 1, 'freeiran': 1} /Users/sumeet_kumar/Library/CloudStorage/OneDrive-IndianSchoolofBusiness/Research_projects/Stance/Stance/stance_dataset/labeled_users/Iran_Deal_labels_combined.txt Iran_Deal\n",
      "<stance_processor.data_extractor.Data object at 0x1114dbc70>\n"
     ]
    }
   ],
   "source": [
    "# Read twitter data and create new files (moslty csv and json files)\n",
    "# dc = DataTablesCreator(tweets_path, event_name, extracted_files_path)\n",
    "# dc.extract_data()\n",
    "\n",
    "# Read the newly created files and load them to memory\n",
    "event_predicted_user_stance = {}\n",
    "event_predicted_user_stance_conf = {}\n",
    "event_table_data = {}\n",
    "\n",
    "for event_name in ['Student_Marches', 'Santa_Fe_Shooting',  'Iran_Deal']:\n",
    "    \n",
    "    seed_tag_labels = event_seed_tag_labels[event_name][1]\n",
    "    print(seed_tag_labels)\n",
    "    \n",
    "    label_file_name = '/Users/sumeet_kumar/Library/CloudStorage/OneDrive-IndianSchoolofBusiness/Research_projects/Stance/Stance/stance_dataset/labeled_users/' + event_name  + '_labels_combined.txt' #If not, leave blank    \n",
    "    \n",
    "    event_data = DataTablesExtractor.get_event_data(all_events = [event_name], # 'open_us',\n",
    "                                 output_path = results_path, #timeline\n",
    "                                 data_folder = extracted_files_path ,\n",
    "                                label_folder_path = '/Users/sumeet_kumar/Library/CloudStorage/OneDrive-IndianSchoolofBusiness/Research_projects/Stance/Stance/stance_dataset/labeled_users/',\n",
    "                               label_file_extension =  '_labels_combined.txt' ,\n",
    "                               use_labeled_users_only = False)    #\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Set the parameters for the model\n",
    "    print(seed_tag_labels, label_file_name, event_name )\n",
    "    dataJson = event_data[event_name] # loadBiasWatchJson(folder_path, text_file_name, label_file_name )\n",
    "    \n",
    "    \n",
    "    args = {}\n",
    "    args['binarize'] = False\n",
    "    args['retweet_count'] = 5000\n",
    "    args['hashtag_count'] = 250#250\n",
    "    args['inner_iteration_count']  = 5\n",
    "    args['iteration_count'] = 3\n",
    "    args['property_type'] = 2\n",
    "\n",
    "    args['text_threshold'] = 0.85 # 0.65         \n",
    "    args['property_confidence_threshold'] = 0.8\n",
    "    args['confidence_threshold_for_mixing'] = 0.7\n",
    "    mixing_percent = args['mixing_percent'] = 0.05\n",
    "\n",
    "    args['seed_tag_labels'] = seed_tag_labels        \n",
    "    args['name'], args['clf'], args['parameters'] =  ('svm12', Pipeline([('vect', CountVectorizer()),\n",
    "                                         ('tfidf', TfidfTransformer()),\n",
    "                                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                                                   alpha=1e-3, max_iter=15, random_state=42)),\n",
    "                                        ])\n",
    "                                    , {'vect__ngram_range': [(1, 1), (1, 2)], \n",
    "                                      'tfidf__use_idf': (True, False),\n",
    "                                      'clf-svm__alpha': (1e-2, 1e-3),\n",
    "                                     })\n",
    "\n",
    "    args['experiment_type'] = event_name\n",
    "    args['dataJson'] = dataJson        \n",
    "\n",
    "    args['results_path'] = results_path\n",
    "    \n",
    "    \n",
    "    print(dataJson)\n",
    "\n",
    "\n",
    "    # Run the model that creates output files\n",
    "#     predicted_user_stance, predicted_user_stance_conf = run_cotrain_experiments(args)\n",
    "\n",
    "\n",
    "#     event_predicted_user_stance[event_name] = predicted_user_stance\n",
    "    \n",
    "#     event_predicted_user_stance_conf[event_name] = predicted_user_stance_conf    \n",
    "    event_table_data[event_name] = event_data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e0218f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Student_Marches', 'Santa_Fe_Shooting', 'Iran_Deal'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_table_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7029f049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1092\n",
      "3347\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/df_all_data.csv', dtype={'target_user': object, 'response_user': object})\n",
    "\n",
    "users_of_interest = {}\n",
    "for user in df['target_user']:\n",
    "    users_of_interest[user] = 1\n",
    "\n",
    "print(len(users_of_interest))    \n",
    "\n",
    "for user in df['response_user']:\n",
    "    users_of_interest[user] = 1\n",
    "print(len(users_of_interest))        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe8b07ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating hashtag weight matrix\n",
      "hashtags_users:  86653\n",
      "hashtags_users:  580180\n",
      "(71293, 100)\n",
      "(71293, 100)\n"
     ]
    }
   ],
   "source": [
    "# self.user_retweet_count = user_retweet_count\n",
    "#         self.user_endtag_count = user_endtag_count\n",
    "\n",
    "\n",
    "from os import path\n",
    "\n",
    "# all_events = ['Santa_Fe_Shooting'] # , 'Student_Marches' , 'Iran_Deal'\n",
    "# label_folder_path = '../stance_dataset/contentious_data/'\n",
    "# data_folder = '../stance_dataset/contentious_data/'\n",
    "# label_file_extension = '/endtags_weighted.csv'\n",
    "\n",
    "\n",
    "def add_user_feature_count_to_dict(user_dict, user, feature, count):\n",
    "        try:\n",
    "            if user not in user_dict:\n",
    "                user_dict[user] = {}\n",
    "\n",
    "            user_feature_count =  user_dict[user]\n",
    "\n",
    "            if feature not in user_feature_count:\n",
    "                user_feature_count[feature] = int(count)\n",
    "            else:\n",
    "                user_feature_count[feature] += int(count)\n",
    "        except:\n",
    "            print('error', feature, count)\n",
    "\n",
    "def add_feature_count_to_dict(feature_dict, feature, count):\n",
    "    try:\n",
    "        if feature not in feature_dict:\n",
    "            feature_dict[feature] = int(count)\n",
    "        else:\n",
    "            feature_dict[feature] += int(count)\n",
    "\n",
    "    except:\n",
    "        print('error', feature, count)\n",
    "\n",
    "\n",
    "    \n",
    "def create_vector(user_property_count, tweet_user_index, N_TOP, binarize_count):\n",
    "    user_hashtag_weighted_matrix = np.zeros((len(tweet_user_index), N_TOP))\n",
    "\n",
    "    hashtags_users = {}\n",
    "    hashtag_index = {}\n",
    "    index_to_tag = {}\n",
    "    for user, hashtags_count in user_property_count.items():\n",
    "        for hashtag, count in hashtags_count.items():\n",
    "            if hashtag not in hashtags_users:\n",
    "                hashtags_users[hashtag] = []\n",
    "\n",
    "            hashtags_users[hashtag].append(user)\n",
    "\n",
    "\n",
    "    print('hashtags_users: ', len(hashtags_users))\n",
    "\n",
    "    sorted_hashtags = sorted(hashtags_users.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "\n",
    "    for tag, users in sorted_hashtags[0:N_TOP]:\n",
    "        for user in users:\n",
    "            if user in tweet_user_index:\n",
    "                user_index = tweet_user_index[user]\n",
    "                if tag not in hashtag_index:\n",
    "                    hashtag_index[tag] = len(hashtag_index)\n",
    "                    index_to_tag[len(hashtag_index) - 1] = tag\n",
    "\n",
    "                tag_index = hashtag_index[tag]\n",
    "\n",
    "                if tag in user_property_count[user]:\n",
    "                    user_hastag_time_used = user_property_count[user][tag]\n",
    "\n",
    "                    if binarize_count:\n",
    "                        user_hashtag_weighted_matrix[user_index, tag_index] = 1\n",
    "                    else:\n",
    "                        user_hashtag_weighted_matrix[user_index, tag_index] = user_hastag_time_used\n",
    "\n",
    "#     if normalize_row:\n",
    "#         normalized_user_hashtag_weighted_matrix = TextProcessingHelpers.row_normalize(user_hashtag_weighted_matrix)\n",
    "#     else:\n",
    "    normalized_user_hashtag_weighted_matrix = user_hashtag_weighted_matrix\n",
    "\n",
    "    return normalized_user_hashtag_weighted_matrix, hashtag_index, index_to_tag\n",
    "\n",
    "\n",
    "tweet_user_index = {}\n",
    "tweet_user_index_to_id = {}\n",
    "\n",
    "user_retweet_count_all= {}\n",
    "user_endtag_count_all = {}\n",
    "for event_name in ['Student_Marches', 'Santa_Fe_Shooting', 'Iran_Deal']: # ]:\n",
    "\n",
    "    # user_tweet_count = event_table_data['Student_Marches']['Student_Marches'].user_tweet_count\n",
    "    user_retweet_count = event_table_data[event_name][event_name].user_retweet_count\n",
    "    user_endtag_count = event_table_data[event_name][event_name].user_endtag_count\n",
    "\n",
    "    for user, count in user_endtag_count.items():\n",
    "        if (user not in tweet_user_index and sum(count.values()) > 5) or (user not in tweet_user_index and user in users_of_interest):\n",
    "            tweet_user_index_length = len(tweet_user_index)\n",
    "            tweet_user_index[user] = tweet_user_index_length\n",
    "            tweet_user_index_to_id[tweet_user_index_length] = user\n",
    "\n",
    "\n",
    "    for user, count in user_retweet_count.items():\n",
    "        if (user not in tweet_user_index and sum(count.values()) > 5) or (user not in tweet_user_index and user in users_of_interest):\n",
    "            tweet_user_index_length = len(tweet_user_index)\n",
    "            tweet_user_index[user] = tweet_user_index_length\n",
    "            tweet_user_index_to_id[tweet_user_index_length] = user\n",
    "            \n",
    "    user_retweet_count_all = {**user_retweet_count_all, **user_retweet_count}\n",
    "    user_endtag_count_all = {**user_endtag_count_all, **user_endtag_count}\n",
    "            \n",
    "            \n",
    "\n",
    "print('Creating hashtag weight matrix')\n",
    "user_hashtag_weighted_matrix, hashtag_index, index_to_tag = create_vector(user_endtag_count,\n",
    "                                                                          tweet_user_index,\n",
    "                                                                          N_TOP = 100,\n",
    "                                                                          binarize_count = False)\n",
    "\n",
    "\n",
    "user_retweet_weighted_matrix, retweet_index, index_to_retweet = create_vector(user_retweet_count,\n",
    "                                                                          tweet_user_index,\n",
    "                                                                          N_TOP = 100,\n",
    "                                                                          binarize_count = False)\n",
    "\n",
    "\n",
    "\n",
    "print(np.shape(user_hashtag_weighted_matrix))\n",
    "\n",
    "print(np.shape(user_retweet_weighted_matrix))\n",
    "\n",
    "# Creating hashtag weight matrix\n",
    "# hashtags_users:  86653\n",
    "# hashtags_users:  580180\n",
    "# (70560, 100)\n",
    "# (70560, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c27704e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71293, 71293)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sum(user_endtag_count['2496463412'].values())\n",
    "# np.sum(user_hashtag_weighted_matrix, axis=1)\n",
    "# np.sum(user_retweet_weighted_matrix, axis=1)\n",
    "# print(np.shape(user_hashtag_weighted_matrix))\n",
    "\n",
    "user_user_matrix = np.dot(user_hashtag_weighted_matrix, user_hashtag_weighted_matrix.T)\n",
    "\n",
    "print(np.shape(user_user_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "481944dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71293, 71293)\n"
     ]
    }
   ],
   "source": [
    "user_user_matrix2 = np.dot(user_retweet_weighted_matrix, user_retweet_weighted_matrix.T)\n",
    "\n",
    "print(np.shape(user_user_matrix2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef0ca030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71293, 71293)\n"
     ]
    }
   ],
   "source": [
    "user_user_matrix_joint = user_user_matrix + user_user_matrix2\n",
    "\n",
    "print(np.shape(user_user_matrix_joint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c529b5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/user_user_matrix_joint.npy', user_user_matrix_joint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "468f0cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  1657469888 0\n",
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 54121, Edges: 1657469888\n",
      "\n",
      " Node types:\n",
      "  default: [54121]\n",
      "    Features: none\n",
      "    Edge types: default-default->default\n",
      "\n",
      " Edge types:\n",
      "    default-default->default: [1657469888]\n",
      "        Weights: range=[1, 2.49968e+06], mean=40.1005, std=3026.22\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from stellargraph import StellarGraph\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import stellargraph as sg\n",
    "# from stellargraph.mapper import FullBat\n",
    "\n",
    "k = 0\n",
    "I, J = np.shape(user_user_matrix_joint)\n",
    "\n",
    "sources = []\n",
    "targets = []\n",
    "weights = []\n",
    "indicies = []\n",
    "\n",
    "# square_node_data = pd.DataFrame(\n",
    "#     {\"x\": [1, 2, 3, 4], \"y\": [-0.2, 0.3, 0.0, -0.5]}, index=[\"a\", \"b\", \"c\", \"d\"]\n",
    "# )\n",
    "# square_node_data\n",
    "\n",
    "user_features= {}\n",
    "for i in range(0, I):\n",
    "    for j in range(0, J):\n",
    "\n",
    "        if i!= j and user_user_matrix[i, j] > 0:\n",
    "            user1 = tweet_user_index_to_id[i]\n",
    "            sources.append(user1)\n",
    "            \n",
    "#             if user1 not in user_features:\n",
    "#                 user_features[user1] = np.zeros(10).tolist()\n",
    "                \n",
    "            user2 = tweet_user_index_to_id[j]\n",
    "            targets.append(user2)\n",
    "            \n",
    "#             if user2 not in user_features:\n",
    "#                 user_features[user2] = np.zeros(10).tolist()\n",
    "            \n",
    "            \n",
    "            weights.append(user_user_matrix[i, j])\n",
    "\n",
    "            k += 1\n",
    "        \n",
    "print('k: ', k, len(user_features))   \n",
    "\n",
    "event_edges = pd.DataFrame(\n",
    "    {\"source\": sources, \"target\": targets, \"weight\":weights }\n",
    ")\n",
    "\n",
    "G = StellarGraph(edges= event_edges)\n",
    "print(G.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f845480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of random walks: 270605\n"
     ]
    }
   ],
   "source": [
    "from stellargraph.data import BiasedRandomWalk\n",
    "\n",
    "rw = BiasedRandomWalk(G)\n",
    "\n",
    "walks = rw.run(\n",
    "    nodes=list(G.nodes()),  # root nodes\n",
    "    length=10,  # maximum length of a random walk\n",
    "    n=5,  # number of random walks per root node\n",
    "    p=0.5,  # Defines (unormalised) probability, 1/p, of returning to source node\n",
    "    q=2.0,  # Defines (unormalised) probability, 1/q, for moving away from source node\n",
    ")\n",
    "print(\"Number of random walks: {}\".format(len(walks)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40ea3b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "str_walks = [[str(n) for n in walk] for walk in walks]\n",
    "model = Word2Vec(str_walks, vector_size=128, window=5, min_count=0, sg=1, workers=4)\n",
    "# The embedding vectors can be retrieved from model.wv using the node ID.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c081c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54121 <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Retrieve node embeddings and corresponding subjects\n",
    "node_ids = model.wv.index_to_key  # list of node IDs\n",
    "node_embeddings = (\n",
    "    model.wv.vectors\n",
    ")  # numpy.ndarray of size number of nodes times embeddings dimensionality\n",
    "\n",
    "\n",
    "print(len(node_ids), type(node_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6cf19b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('./data/node_embeddings_128_v2.text', binary=False)\n",
    "\n",
    "# from gensim.models import KeyedVectors\n",
    "\n",
    "# save_word2vec_format()\n",
    "\n",
    "# kv = KeyedVectors(128)\n",
    "\n",
    "# kv.add(node_ids, node_embeddings)\n",
    "# kv.save('./data/node_embeddings_128.kvmodel')\n",
    "# # You could then later re-load these via:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e11f825",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/node_embeddings_128.kvmodel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c4/z6xs643x2dlf5_h1t65gjzc00000gp/T/ipykernel_15282/1066899059.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/node_embeddings_128.kvmodel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_lifecycle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \"\"\"\n\u001b[0;32m-> 1460\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1461\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# needed because loading from S3 doesn't support readline()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     fobj = _shortcut_open(\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/node_embeddings_128.kvmodel'"
     ]
    }
   ],
   "source": [
    "# kv2 = KeyedVectors.load('../data/node_embeddings_128.kvmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb0533c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model1 = Word2Vec(str_walks, vector_size=64, window=5, min_count=0, sg=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41814061",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.wv.save_word2vec_format('./data/node_embeddings_64_v2.text', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1cd36bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model2 = Word2Vec(str_walks, vector_size=16, window=5, min_count=0, sg=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03c2f654",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.wv.save_word2vec_format('./data/node_embeddings_16_v2.text', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "705c166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model3 = Word2Vec(str_walks, vector_size=8, window=5, min_count=0, sg=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "300d12b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.wv.save_word2vec_format('./data/node_embeddings_8_v2.text', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "492275f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53847"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(node_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c58f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(node_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136dc4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "node_targets = node_subjects.loc[[int(node_id) for node_id in node_ids]]\n",
    "\n",
    "transform = TSNE  # PCA\n",
    "\n",
    "trans = transform(n_components=2)\n",
    "node_embeddings_2d = trans.fit_transform(node_embeddings)\n",
    "\n",
    "\n",
    "# draw the embedding points, coloring them by the target label (paper subject)\n",
    "alpha = 0.7\n",
    "# label_map = {l: i for i, l in enumerate(np.unique(node_targets))}\n",
    "# node_colours = [label_map[target] for target in node_targets]\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.axes().set(aspect=\"equal\")\n",
    "plt.scatter(\n",
    "    node_embeddings_2d[:, 0],\n",
    "    node_embeddings_2d[:, 1],\n",
    "#     c=node_colours,\n",
    "    cmap=\"jet\",\n",
    "    alpha=alpha,\n",
    ")\n",
    "plt.title(\"{} visualization of node embeddings\".format(transform.__name__))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
